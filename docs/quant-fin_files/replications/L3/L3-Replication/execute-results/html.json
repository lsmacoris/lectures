{
  "hash": "1277e758292af328ab4b967bbd3a319f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Manipulating Time Series\"\nauthor: \"Lucas S. Macoris (FGV-EAESP)\"\nformat:\n  html:\n    page-layout: full\neditor: visual\n---\n\n\n\n\n## About this Document\n\nThis file replicates the codes that have been discussed in the live-session lectures of the Practical Applications in Quantitative Finance course. To ensure you can run the codes without issues, please install and load all required packages beforehand. It is always a good practice to replicate this Quarto document and experiment by making edits to the parameters. At the end of this report, you will find a suggestion on how to tweak this report — try doing some changes on your own!\n\n::: callout-important\n### Attention\n\nIn this lecture, we will be working with daily stock price data from several stocks included in the *S&P 500* index. Instead of loading the data from a `.csv` file, we will pull the data *directly* from R using the `tidyquant` package. Before you start, make sure to follow the instructions from our previous replication to set up your working directory correctly.\n:::\n\n## Loading packages\n\nAs we get started, we will be loading all packages referred in our official [website](https://lsmacoris.github.io/lectures/quant-fin.html).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Package names\npackages <- c(\"tidyverse\",\"tidyquant\",\"tidymodels\", \"glue\",\"scales\",\"ggthemes\")\n\n# Install packages not yet installed\ninstalled_packages <- packages %in% rownames(installed.packages())\n\nif (any(installed_packages == FALSE)) {\n  install.packages(packages[!installed_packages])\n}\n\n# Load all packages\ninvisible(lapply(packages, library, character.only = TRUE))\n```\n:::\n\n\n\n\nNote that you could easily get around this by installing and loading all necessary packages using a more simple syntax:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Install if not already available - I have commented these lines so that R does not attempt to install it everytime\n  #install.packages('tidyverse')\n  #install.packages('tidyquant')\n  #install.packages('glue')\n  #install.packages('scales')\n  #install.packages('ggthemes')\n\n#Load\n  library(tidyverse)\n  library(tidyquant)\n  library(tidymodels)\n  library(glue)\n  library(scales)\n  library(ggthemes)\n```\n:::\n\n\n\n\n## Working with Time Series\n\n\nIn the previous lectures, you worked your way through the exercises by using the amazing `dplyr` functionalities on `data.frames`. In some cases, however, you had to do some workarounds with `drop_na()`, `slice_tail()` and `lag()` simply because you were manipulating time series data.\n\nThe `xts`, which stantds for *eXtensible Time Series* is an `R` package that is is widely used for handling and manipulating time series data. It extends the functionality of the zoo package by providing a structured framework for managing time-indexed data efficiently. Such package provides a matrix-like structure where each row is indexed by a date-time value, allowing for efficient subsetting, merging, and manipulation of time series data. It is especially useful in financial applications where time-stamped data is common.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(xts) # Note that this is loaded together with the tidyquant package\n\n# Create a vector of random values\ndata_values <- rnorm(10)\n\n# Create a sequence of dates\ndates <- as.Date(\"2024-01-01\") + 0:9\n\n# Convert to xts\nxts_data <- xts(data_values, order.by = dates)\n\n# Print the xts object\nprint(xts_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 [,1]\n2024-01-01 -0.8782227\n2024-01-02 -0.4597098\n2024-01-03 -0.3964338\n2024-01-04 -1.0016150\n2024-01-05 -1.5862849\n2024-01-06 -0.1767326\n2024-01-07 -0.9713712\n2024-01-08  0.3229833\n2024-01-09 -1.7203924\n2024-01-10 -0.7158226\n```\n\n\n:::\n:::\n\n\n\n\nThe output shows an interesting feature of an `xts` format in R:\n\n1. The first column contains the values\n2. The row names are timestamps\n3. The `xts` object retains an efficient internal structure\n\n## Core features of `xts`\n\n- **Time-Based Indexing & Subsetting**: you can subset an `xts` object using time-based indexing in a variety of ways. If you were to do this in a `data.frame`, R wouldn't be able to retrieve the data, as a `data.frame` does not carry any time series properties that are needed for the job:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Subset a specific date\nxts_data[\"2024-01-03\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 [,1]\n2024-01-03 -0.3964338\n```\n\n\n:::\n\n```{.r .cell-code}\n# Subset a range\nxts_data[\"2024-01-03/2024-01-06\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 [,1]\n2024-01-03 -0.3964338\n2024-01-04 -1.0016150\n2024-01-05 -1.5862849\n2024-01-06 -0.1767326\n```\n\n\n:::\n\n```{.r .cell-code}\n# Subset a custom Y-M-D definition\nxts_data[\"2024\"]       # Returns all data from 2024\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 [,1]\n2024-01-01 -0.8782227\n2024-01-02 -0.4597098\n2024-01-03 -0.3964338\n2024-01-04 -1.0016150\n2024-01-05 -1.5862849\n2024-01-06 -0.1767326\n2024-01-07 -0.9713712\n2024-01-08  0.3229833\n2024-01-09 -1.7203924\n2024-01-10 -0.7158226\n```\n\n\n:::\n\n```{.r .cell-code}\nxts_data[\"2024-01\"]    # Returns all data from January 2024\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 [,1]\n2024-01-01 -0.8782227\n2024-01-02 -0.4597098\n2024-01-03 -0.3964338\n2024-01-04 -1.0016150\n2024-01-05 -1.5862849\n2024-01-06 -0.1767326\n2024-01-07 -0.9713712\n2024-01-08  0.3229833\n2024-01-09 -1.7203924\n2024-01-10 -0.7158226\n```\n\n\n:::\n:::\n\n\n\n\n- **Merging and Combining Time Series**: you can merge two `xts` objects using by the timestamp component that is embedded in the `xts` structure:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata1 <- xts(rnorm(5), order.by = as.Date(\"2024-01-01\") + 0:4)\ndata2 <- xts(rnorm(5), order.by = as.Date(\"2024-01-01\") + 2:6)\n\nmerged_data <- merge(data1, data2, join = \"outer\")\nprint(merged_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                data1       data2\n2024-01-01 -0.3247350          NA\n2024-01-02 -0.4150009          NA\n2024-01-03  1.4498303 -1.47773093\n2024-01-04  1.6398024  0.41617149\n2024-01-05 -0.9977372 -0.06436564\n2024-01-06         NA  0.81567706\n2024-01-07         NA  1.17189255\n```\n\n\n:::\n:::\n\n\n\n\n- `join = \"outer\"` ensures all time points are included\n- If a time point is missing in one dataset, it is filled with `NA`\n\n- **Merging and Combining Time Series**: using functions that retrieve leads and lags of a given variable are a key component of `xts` objects. Due to its timestamp component, one can shift variables backwards (using the `lag()` function) as well as forward (using the `lag()`) function:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlagged_data <- lag(data1)  # Shift values by 1 day\nprint(lagged_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 [,1]\n2024-01-01         NA\n2024-01-02 -0.3247350\n2024-01-03 -0.4150009\n2024-01-04  1.4498303\n2024-01-05  1.6398024\n```\n\n\n:::\n\n```{.r .cell-code}\nmerged_data <- merge(lagged_data, data1, join = \"outer\")\nprint(merged_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           lagged_data      data1\n2024-01-01          NA -0.3247350\n2024-01-02  -0.3247350 -0.4150009\n2024-01-03  -0.4150009  1.4498303\n2024-01-04   1.4498303  1.6398024\n2024-01-05   1.6398024 -0.9977372\n```\n\n\n:::\n:::\n\n\n\n\nAll in all, when it comes to working with financial data, `xts` objects are particularly useful for:\n\n1. Handling stock price data from `tidyquant`\n2. Calculating log returns for portfolio management\n3. Aligning time series data (*e.g.*, joining different financial datasets)\n4. Aggregating financial data (*e.g.*, monthly returns)\n5. Subsetting data by years/months/days\n6. Calculating rolling functions (*e.g*, yearly averages)\n7. Aggregating data at different intervals (*e.g*, convert daily to weekly prices)\n\n\nUnfortunately, there is an issue: the `tidyverse` is not fully designed to work with time series classes, such as `xts`. Since `xts` is optimized for time series operations, some functions that would work well when managing time series are not easily translated using the packages from the `tidyverse`:\n\n1. `tidyverse`: Designed for tabular (data frame-like) structures, emphasizing \"tidy\" data (each row is an observation, each column is a variable)\n\n2. `xts`: Designed for time series, optimizing time-based indexing and calculations but less compatible with tidyverse workflows\n\n## Introducing the `tidyquant` package\n\nThe `tidyquant` package (see official documentation [here](https://business-science.github.io/tidyquant/index.html)) helps integrate both paradigms, making financial analysis more intuitive in R. It integrates several financial packages, like `zoo`, `xts`, `quantmod`, `TTR`, and `PerformanceAnalytics`, with the tidy data infrastructure of the `tidyverse`, allowing for seamless interaction between `tidyverse` data manipulation and financial functions.\n\nThere are mainly *three* functions in the `tidyquant` package that we will be using throughout this lecture: `tq_get()`, `tq_mutate()`, and `tq_transmute()`.\n\n## The `tq_get()` function\n\n::: callout-tip\n### Definition\n\nThe `tq_transmute()` returns only newly created columns and is typically used when periodicity changes. Its syntax is the following:\n\nThe `tq_get()` function is a powerful tool for retrieving financial data in a tidy format. It provides an easy way to import stock prices, economic data, and key financial metrics from multiple sources, including *Yahoo Finance*, *FRED*, *Alpha Vantage*, and *Quandl*.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntq_get(x, get = \"stock.prices\", from = NULL, to = NULL, ...)\n```\n:::\n\n\n\n\n- `x`:\ta character string or vector specifying the stock symbol(s) or identifier(s)\n- `get`:\tthe type of data to retrieve. Defaults to `\"stock.prices\"`\n- `from`:\tstart date, in YYYY-MM-DD format. Defaults to `NULL` (gets all available data)\n- `to`:\tend date, in YYYY-MM-DD format. Defaults to `NULL` (gets all available data)\n- `...`: additional arguments specific to the data source\n\n:::\n\nOne of the most common uses of `tq_get()` is fetching stock price data. Say, for example, that you want to fetch data from *Apple* between January and February for 2024. It is easy to use `tq_get()` to retrieve such information:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Assuming you have the tidyquant loaded in your session\n\n# Fetch Apple (AAPL) stock data from 2024-01-01 to 2024-02-01\naapl_data <- tq_get(\"AAPL\", from = \"2024-01-01\", to = \"2024-02-01\")\n\n# Print first few rows\nhead(aapl_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 8\n  symbol date        open  high   low close   volume adjusted\n  <chr>  <date>     <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n1 AAPL   2024-01-02  187.  188.  184.  186. 82488700     185.\n2 AAPL   2024-01-03  184.  186.  183.  184. 58414500     183.\n3 AAPL   2024-01-04  182.  183.  181.  182. 71983600     181.\n4 AAPL   2024-01-05  182.  183.  180.  181. 62303300     180.\n5 AAPL   2024-01-08  182.  186.  182.  186. 59144500     184.\n6 AAPL   2024-01-09  184.  185.  183.  185. 42841800     184.\n```\n\n\n:::\n:::\n\n\n\n\n- The result is a tidy `tibble`, unlike quantmod’s `xts` format.\n\n## The `tq_mutate()` function\n\n::: callout-tip\n### Definition\n\nThe `tq_mutate()` function adds adds new variables to an existing `tibble`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntq_mutate(.data, #The object you are performing the calculations \n       selected_variables, #The columns to send to the mutation function\n       mutate_fun, #The mutation function from either the xts, quantmod, or TTR package.\n       col_rename #A string or character vector containing names that can be used to quickly rename columns\n       ) \n```\n:::\n\n\n\n:::\n\n1.  The main advantage is the results are returned as a `tibble` and the function can be used with the `tidyverse`\n2.  It is used when you expected additional columns to be added to the resulting data frame\n3.  You can use several time series related functions from other `R` packages - call `tq_mutate_fun_options()` to see the list of available options\n4.  All in all, it is similar in spirit to `mutate()`\n\n## The `tq_transmute()` function\n\n::: callout-tip\n### Definition\n\nThe `tq_transmute()` returns only newly created columns and is typically used when periodicity changes. Its syntax is the following:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntq_mutate(.data, #The object you are performing the calculations \n       selected_variables, #The columns to send to the mutation function\n       mutate_fun, #The mutation function from either the xts, quantmod, or TTR package.\n       col_rename #A string or character vector containing names that can be used to quickly rename columns\n       )\n```\n:::\n\n\n\n:::\n\n1.  `tq_transmute()` works exactly like `tq_mutate()` except it only returns the newly created columns\n2.  This is helpful when changing periodicity where the new columns would not have the same number of rows as the original tibble\n3.  All in all, it is similar in spirit to `summarize()`\n\n## Working with time series objects\n\nAn immediate useful example of using a time series specific functionality with a tidyverse logic relates to [filtering]{.blue}. Sometimes, we may be interested in getting only a subset of the data (for example, only *GOOG* information). Furthermore, we may be interested in subsetting only a specific time frame for our analysis\n\n\nIt is relatively straightforward to do it with `tidyquant`:\n\n1.  Use `filter()` to select only rows where `symbol=='GOOG'`\n2.  In the same call, filter for `date>= min_date` and `date<=max_date`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Assuming you have the tidyverse and the tidyquant packages loadded\n\n#Set up the list of assets\nassets=c('AMZN','GOOG','META','GME')\n\n#Filter out\nassets%>%\n  tq_get()%>%\n  filter(symbol=='GOOG',\n         date>='2020-01-01',\n         date<='2024-12-31')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,258 × 8\n   symbol date        open  high   low close   volume adjusted\n   <chr>  <date>     <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n 1 GOOG   2020-01-02  67.1  68.4  67.1  68.4 28132000     68.1\n 2 GOOG   2020-01-03  67.4  68.6  67.3  68.0 23728000     67.8\n 3 GOOG   2020-01-06  67.5  69.8  67.5  69.7 34646000     69.5\n 4 GOOG   2020-01-07  69.9  70.1  69.5  69.7 30054000     69.4\n 5 GOOG   2020-01-08  69.6  70.6  69.5  70.2 30560000     70.0\n 6 GOOG   2020-01-09  71.0  71.4  70.5  71.0 30018000     70.7\n 7 GOOG   2020-01-10  71.4  71.7  70.9  71.5 36414000     71.2\n 8 GOOG   2020-01-13  71.8  72.0  71.3  72.0 33046000     71.7\n 9 GOOG   2020-01-14  72.0  72.1  71.4  71.5 31178000     71.3\n10 GOOG   2020-01-15  71.5  72.1  71.5  72.0 25654000     71.7\n# ℹ 1,248 more rows\n```\n\n\n:::\n:::\n\n\n\n\nAnother example of using a time series specific functionality is working with leads and lags: sometimes, we need to shift our variables by a specific interval, like getting the previous day's price. Say, for example, that you want to understand how *S&P* returns levels relate to *NFLX* returns one-week ahead. It is relatively straightforward to do it with `tidyquant`:\n\n1.  Download *S&P 500* and *NFLX* data using the `tq_get()` function\n2.  Use `tq_transmute()` to compute the weekly returns for each security based on daily data\n3.  Use `tq_mutate()` to generate a lagged series of *S&P 500* returns\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Assuming you have the tidyverse and the tidyquant packages loadded\n\n#Netflix Data\nNFLX=tq_get('NFLX')%>%\n  #Select only the necessary columns\n  select(date,symbol,adjusted)%>%\n  #Apply the weeklyReturn function and call the new column 'NFLX'\n  tq_transmute(mutate_fun = weeklyReturn,\n               col_rename = 'NFLX')\n\n#S&P Data\nSP500=tq_get('^GSPC')%>%\n  #Select only the necessary columns\n  select(date,symbol,adjusted)%>%\n  #Apply the weeklyReturn function and call the new column 'SP500'\n  tq_transmute(mutate_fun = weeklyReturn,\n               col_rename = 'SP500')%>%\n  #Apply the lag function for n=1 week and call the new column 'SP500'\n  tq_transmute(mutate_fun = lag.xts,\n            n=1,\n            col_rename = 'SP500')%>%\n  #Drop all rows with NA information (row 1, in this case)\n  drop_na()\n\n#Merge Data \ninner_join(NFLX,SP500)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(date)`\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 530 × 3\n   date           NFLX    SP500\n   <date>        <dbl>    <dbl>\n 1 2015-01-09 -0.0563   0      \n 2 2015-01-16  0.0244  -0.00651\n 3 2015-01-23  0.297   -0.0124 \n 4 2015-01-30  0.00992  0.0160 \n 5 2015-02-06  0.00579 -0.0277 \n 6 2015-02-13  0.0489   0.0303 \n 7 2015-02-20  0.0260   0.0202 \n 8 2015-02-27 -0.00688  0.00635\n 9 2015-03-06 -0.0438  -0.00275\n10 2015-03-13 -0.0346  -0.0158 \n# ℹ 520 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Rolling functions\n\nFinance practitioners are often asked to perform analysis on a rolling basis: we may want to calculate a given signal on day $t$ based on past $x$ periods of information. Say, for example, that you want to calculate a simple and exponential moving average of adjusted prices from 5 days back for a given stock. It is relatively straightforward to do it with `tidyquant`:\n\n1.  Download stock data using the `tq_get()` function\n2.  Use `tq_mutate()` twice along with the `SMA()` and `EMA()` functions setting `n=5`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Assuming you have the tidyverse and the tidyquant packages loadded\n\n#Set up the list of assets\nassets=c('AMZN')\n\nassets%>%\n  tq_get()%>%\n  select(date,symbol,adjusted)%>%\n  group_by(symbol)%>%\n  tq_mutate(adjusted, mutate_fun = SMA, n = 5)%>%\n  tq_mutate(adjusted, mutate_fun = EMA, n = 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2,551 × 5\n# Groups:   symbol [1]\n   symbol date       adjusted   SMA   EMA\n   <chr>  <date>        <dbl> <dbl> <dbl>\n 1 AMZN   2015-01-02     15.4  NA    NA  \n 2 AMZN   2015-01-05     15.1  NA    NA  \n 3 AMZN   2015-01-06     14.8  NA    NA  \n 4 AMZN   2015-01-07     14.9  NA    NA  \n 5 AMZN   2015-01-08     15.0  15.0  15.0\n 6 AMZN   2015-01-09     14.8  14.9  15.0\n 7 AMZN   2015-01-12     14.6  14.8  14.8\n 8 AMZN   2015-01-13     14.7  14.8  14.8\n 9 AMZN   2015-01-14     14.7  14.8  14.8\n10 AMZN   2015-01-15     14.3  14.6  14.6\n# ℹ 2,541 more rows\n```\n\n\n:::\n:::\n\n\n\n\nLastly, financial analysts often cover a collection of securities on a rolling basis. For example, a buy-side analyst will monitor stocks from a given industry so as to understand which ones are [over]{.red}valued, and which ones are [under]{.green}valued. Say, for example, that you want to focus on a subset of 4 stocks, and you need to compare the cumulative return up to the latest closing price. \n\nIt is easy to integrate the `tidyquant` functions along with the `group_by()` function you've learned when working with `dplyr`:\n\n1. Get the information using `tq_get()`\n2. Group the data by `symbol`\n3. Apply the `tq_mutate` and `tq_transmute` functions to pass time series functions to the data - in this case, the `dailyReturn()` and the `Return.cumulative()` function\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Assuming you have the tidyverse and the tidyquant packages loadded\n\n#Set up the list of assets\nassets=c('AMZN','GOOG','META','GME')\n\nassets%>%\n  tq_get()%>%\n  select(date,symbol,adjusted)%>%\n  group_by(symbol)%>%\n  tq_mutate(adjusted, mutate_fun = dailyReturn,col_rename = 'daily_return')%>%\n  tq_transmute(daily_return,mutate_fun = Return.cumulative)%>%\n  mutate(across(where(is.numeric),percent,big.mark='.'))%>%\n  setNames(c('Ticker','Cumulative Return up-to-date'))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: There were 5 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `across(where(is.numeric), percent, big.mark = \".\")`.\nℹ In group 1: `symbol = \"AMZN\"`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\nℹ Run `dplyr::last_dplyr_warnings()` to see the 4 remaining warnings.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 2\n# Groups:   Ticker [4]\n  Ticker `Cumulative Return up-to-date`\n  <chr>  <chr>                         \n1 AMZN   1.279%                        \n2 GOOG   595%                          \n3 META   755%                          \n4 GME    298%                          \n```\n\n\n:::\n:::\n\n\n\n\n## Hands-on Exercise\n\nYour manager (who did not lift any weights past the last 5 years) wanted to replicate the returns of the *Deadlift ETF* from 2020 to 2024. You job is to create a simple table of yearly returns comparing the *Deadlift ETF* *vis-a-vis* the *S&P 500* Index. Follow the instructions and answer to the following questions:\n\n  1. **When looking at the yearly results from both the *Deadlift ETF* and *S&P 500*, which one did perform better?**\n  2. **What are the potential explanations for the result you have found?**\n\nTo answer to these questions, you will be using the a combination of `dplyr` and `tidyquant` functions you have learned so far. The expected result is a `data.frame` object that shows both the *Deadlift ETF* as well as the *S&P 500* returns (columns) on a yearly basis (rows).\n\n::: callout-tip\n### Instructions\n\nBefore you start, make sure to have the `tidyverse` and the `tidyquant` packages loaded in your session. Following the instructions from the previous lectures, you can either make a direct call to each package, `library(tidyverse)` and `library(tidyquant)`, or copy-paste the script from the course's [official website](https://lsmacoris.github.io/lectures/quant-fin).\n\n1.  Use `tq_get()` to load information from the *S&P Index* and the *Deadlift ETF* constituents in two separate objects. You can use the code `^GSPC` to retrieve information for the index, and you can pass a vector `c('ticker1','ticker2',...,'ticker_n')` to get information on the *Deadlift ETF* constituents\n2.  Filter for observations starting between 2020 (beginning of) and 2024 (end of) using the `from` and `to` arguments of the `tq_get()` function\n3. Group the *Deadlift ETF* data by `symbol` using the `group_by()` function\n4. For both data sets, create a `yearly_ret` variable that calculates the yearly return of a given security. You can use the `tq_transmute()` function, passing the `yearlyReturn()` function along the chain\n5. For the *Deadlift* data set, regroup the data by `date` and calculate the *Deadlift* returns using a `mutate()` function (*Hint: it is an equally weighted portfolio*) \n6. Merge both datasets using `inner_join()`\n:::\n\n\n## Solution walkthrough\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Assuming you have the tidyverse and the tidyquant packages loadded\n\n# Set up the list of assets\ndeadlift=c('META','AMZN','GS','UBER','MSFT','AAPL','BLK','NVDA')\n\n#Set up the starting date\nstart='2020-01-01'\nend='2024-12-31'\n\n#Step 1: Read the Deadlift data using tidyquant\nDeadlift_Performance=deadlift%>%\n  tq_get(from=start,to=end)%>%\n  #Select only the columns of interest\n  select(symbol,date,adjusted)%>%\n  #Group by symbol and date\n  group_by(symbol)%>%\n  #Use tq_transmute to aggregate and calculate weekly returns\n  tq_transmute(selected=adjusted,\n               mutate_fun=yearlyReturn,\n               col_rename = 'Deadlift')%>%\n  #Group by date\n  group_by(date)%>%\n  #Summarize average return (since it is an equally-weighted portfolio)\n  summarize(Deadlift=mean(Deadlift,na.rm=TRUE))\n\n#Step 2: Read the S&P 500 data using tidyquant\nSP500_Performance=tq_get('^GSPC',from=start,to=end)%>%\n  #Select only the columns of interest\n  select(symbol,date,adjusted)%>%\n  #Group by symbol and date\n  group_by(symbol)%>%\n  #Use tq_transmute to aggregate and calculate weekly returns\n  tq_transmute(selected=adjusted,\n               mutate_fun=yearlyReturn,\n               col_rename = 'SP500')%>%\n  ungroup()%>%\n  select(-symbol)\n    \n#Merge\nSP500_Performance%>%\n  inner_join(Deadlift_Performance)%>%\n  mutate(across(where(is.numeric),percent))%>%\n  mutate(date=year(date))%>%\n  setNames(c('Year','S&P 500','DeadLift ETF'))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(date)`\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 3\n   Year `S&P 500` `DeadLift ETF`\n  <dbl> <chr>     <chr>         \n1  2020 15.29%    57.9%         \n2  2021 26.89%    37.2%         \n3  2022 -19.44%   -36.0%        \n4  2023 24.23%    100.5%        \n5  2024 23.84%    52.1%         \n```\n\n\n:::\n:::\n\n\n\n\nThis solution uses `tidyquant` and `tidyverse` to analyze the yearly returns of a custom portfolio (*i.e.*, the *\"Deadlift ETF\"*) consisting of eight stocks and compares it with the *S&P 500*.\n\n\n1.  **Define Assets and Time Range.** first, we dedfine a custom portfolio (deadlift) containing eight stocks, and set the start and end dates for data collection.\n\n2.  **Fetch & Process the Deadlift Portfolio Returns.** Starting with the *Deadlift ETF*, we first fetch historical stock prices using `tq_get()` for each asset contained in the ETF. After that, we only keep the relevant columns - namely, `symbol`, `date`, and `adjusted`. Using `group_by()` to group by `symbol`, we use the `tq_transmute()` function to apply the `yearlyReturns` function to the `adjusted` column, renaming it as `Deadlift`.\n\n3. **Calculating portfolio returns.** Since this ETF is an equally-weighted portfolio, and using the fact that a portfolio return is a weighted average of the individual securities, you can safely use the `mean()` function to calculate the return of such portfolio. To make sure that the calculation is performed for each year, use `group_by()` again, grouping by `date`.\n\n\n## Try doing some edits on your own!\n\nTry thinking about changes you could do to either improve code readability of the analysis. A couple of edits that can be made include, but are not limited, to:\n\n1. Adding more time periods to the analysis\n2. Contrasting the *DeadLift ETF* with the *S&P 500* in terms of variance and Sharpe Ratio\n3. Doing the comparison using value-weighted returns (*i.e*, weighting the securities inside the portfolio according to its market capitalization) or inverse volatility (*i.e*, riskier assets have lower weights)\n\nPlay around with these concepts to get familiar with all the data manipulation tools that come with the `tidyquant` package!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}