{
  "hash": "65ad63a6542176145a8397235165467b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Collecting, Organizing, and Manipulating Financial Data - Replication\"\nauthor: \"Lucas S. Macoris (FGV-EAESP)\"\nformat:\n  html:\n    page-layout: full\neditor: visual\n---\n\n\n\n\n## About this Document\n\nThis file replicates the codes that have been discussed in the live-session lectures of the Practical Applications in Quantitative Finance course. To ensure you can run the codes without issues, please install and load all required packages beforehand. It is always a good practice to replicate this Quarto document and experiment by making edits to the parameters. At the end of this report, you will find a suggestion on how to tweak this report — try doing some changes on your own!\n\n::: callout-important\n### Attention\n\nIn this lecture, we will be working with daily stock price data from the *Magnificent Seven* (*AAPL*, *GOOG*, *MSFT*, *NVDA*, *TSLA*, *AMZN*, and *META*). I have already downloaded the data for you using the `tidyquant` package, which allows us to pull stock price data from multiple securities in a convenient format. You can hit the *Download* button to get a grasp on how the data looks like or download it directly on *eClass®* - file name: `M7.csv`. Before you start, make sure to follow the instructions from our previous replication to set up your working directory correctly.\n:::\n\n## Loading packages\n\nAs we get started, we will be loading all packages referred in our official [website](https://lsmacoris.github.io/lectures/quant-fin.html).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Package names\npackages <- c(\"tidyverse\",\"tidyquant\",\"tidymodels\", \"glue\",\"scales\")\n\n# Install packages not yet installed\ninstalled_packages <- packages %in% rownames(installed.packages())\n\nif (any(installed_packages == FALSE)) {\n  install.packages(packages[!installed_packages])\n}\n\n# Load all packages\ninvisible(lapply(packages, library, character.only = TRUE))\n```\n:::\n\n\n\n\nNote that you could easily get around this by installing and loading all necessary packages using a more simple syntax:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Install if not already available - I have commented these lines so that R does not attempt to install it everytime\n  #install.packages('tidyverse')\n  #install.packages('tidyquant')\n  #install.packages('glue')\n  #install.packages('scales')\n  #install.packages('ggthemes')\n\n#Load\n  library(tidyverse)\n  library(tidyquant)\n  library(tidymodels)\n  library(glue)\n  library(scales)\n  library(ggthemes)\n```\n:::\n\n\n\n\n## Using `dplyr`, the data manipulation package in the `tidyverse`\n\nThe `dplyr` package is one of the core packages in the `tidyverse` and is designed for efficient and readable data manipulation. It provides a set of functions (also called \"verbs\") that make working with data frames (or tibbles) intuitive and expressive. Key Features:\n\n1.  Filter rows: `filter()`\n2.  Select columns: `select()`\n3.  Mutate (create new columns): `mutate()`\n4.  Summarize data: `summarize()`\n5.  Group operations: `group_by()`\n6.  Join tables: `left_join()`, `right_join()`, `inner_join()`, `full_join()`\n\nTo get started with our exercises, we will refer to the `M7.csv` file that has been provided. After setting the current directory of the file, we load the data using the `read.csv()` function:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Apply function to the data\nM7=read.csv('M7.csv')\n\n#Show the first 10 observations\nhead(M7)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  symbol       date    open    high     low   close    volume adjusted\n1   AAPL 2020-01-02 74.0600 75.1500 73.7975 75.0875 135480400 72.79604\n2   AAPL 2020-01-03 74.2875 75.1450 74.1250 74.3575 146322800 72.08828\n3   AAPL 2020-01-06 73.4475 74.9900 73.1875 74.9500 118387200 72.66272\n4   AAPL 2020-01-07 74.9600 75.2250 74.3700 74.5975 108872000 72.32098\n5   AAPL 2020-01-08 74.2900 76.1100 74.2900 75.7975 132079200 73.48434\n6   AAPL 2020-01-09 76.8100 77.6075 76.5500 77.4075 170108400 75.04523\n```\n\n\n:::\n:::\n\n\n\n\n## 1. The `mutate()` function\n\nThe `mutate()` function adds new variables that are functions of existing variables:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmutate(.data, #The object you are performing the calculations \n       new_variable_1 = var1 * 2, #Can use basic operations...\n       new_variable_2 = median(var2), #Or predefined functions)\n       variable_3 = as.character(var3) #And can be used to modify existing variables)\n       ) \n```\n:::\n\n\n\n\n1.  This function takes the `.data` argument you provided (in your example, the `Data` object)...\n2.  It sequentially creates the columns you asked for and place them to the right of your `data.frame` (or `tibble`)\n3.  You can use any function, predefined or custom, and apply it to `mutate()`\n4.  It can also modify any columns you want (if the name is the same as an existing column)\n\n**Exercise**: use columns `high` and `low` and create a new column, `mid`, defined as the average between daily high and low prices.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Apply function to the data\nM7=mutate(M7, mid= (high+low)/2)\n\n#Show the first 10 observations\nhead(M7)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  symbol       date    open    high     low   close    volume adjusted      mid\n1   AAPL 2020-01-02 74.0600 75.1500 73.7975 75.0875 135480400 72.79604 74.47375\n2   AAPL 2020-01-03 74.2875 75.1450 74.1250 74.3575 146322800 72.08828 74.63500\n3   AAPL 2020-01-06 73.4475 74.9900 73.1875 74.9500 118387200 72.66272 74.08875\n4   AAPL 2020-01-07 74.9600 75.2250 74.3700 74.5975 108872000 72.32098 74.79750\n5   AAPL 2020-01-08 74.2900 76.1100 74.2900 75.7975 132079200 73.48434 75.20000\n6   AAPL 2020-01-09 76.8100 77.6075 76.5500 77.4075 170108400 75.04523 77.07875\n```\n\n\n:::\n:::\n\n\n\n\n## 2. The `select()` function\n\nThe `select()` function select (and optionally rename) variables in a data frame, using a concise mini-language that makes it easy to refer to variables based on their name (*e.g*. `a:f` selects all columns from `a` on the left to `f` on the right) or type (e.g. `where(is.numeric)` selects all numeric columns):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselect(.data, #The object which you are performing the operations \n       variable_3, #Can reorder columns\n       variable_1, \n       variable_2:variable_4, #Matches position patterns \n       where(is.numeric) #Can select all columns that match a given pattern\n       ) \n```\n:::\n\n\n\n\n1.  This function takes the `.data` argument you provided (in your example, the `Data` object)...\n2.  And select only the columns you've asked for\n3.  You can also use `select(.data,-variable)` to remove a variable\n4.  It keeps the structure of the `data.frame` intact - no rows are affected\n\nThe `select()` function also comes with a handy companion of `selectors`, which are functions that help you cherry pick columns in a concise way, rather than hardcoding them altogether:\n\n1.  `:` for selecting a range of consecutive variables.\n2.  `starts_with()` starts with a string\n3.  `ends_with()` ends with a string\n4.  `contains()` contains a string\n5.  `matches()`matches a regular expression.\n6.  `where()`a function to all variables and selects those for which the function returns `TRUE`\n\n**Exercise**: Select only the `symbol`, `date`, `volume`, and `adjusted`, in that order.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Apply function to the data\nM7=select(M7,symbol,date,volume,adjusted)\n\n#Show the first 10 observations\nhead(M7)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  symbol       date    volume adjusted\n1   AAPL 2020-01-02 135480400 72.79604\n2   AAPL 2020-01-03 146322800 72.08828\n3   AAPL 2020-01-06 118387200 72.66272\n4   AAPL 2020-01-07 108872000 72.32098\n5   AAPL 2020-01-08 132079200 73.48434\n6   AAPL 2020-01-09 170108400 75.04523\n```\n\n\n:::\n:::\n\n\n\n\n## 3. The `filter()` function\n\nThe `filter()` function is used to subset a data frame, retaining all rows that satisfy your conditions. To be retained, the row must produce a value of `TRUE` for all conditions:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfilter(.data, #The object which you are performing the operations\n       variable_1 >10, #Simple arithmetic operators\n       variable_2 %in% c('AAPL','MSFT','FORD'), #Pattern search\n       !(variable_3 %in% c('Boston','Mass','Silicon Valley')), #Negate pattern search\n       variable_4 >=10 & variable_3<= 4 | is.na(variable_4) #IF and OR conditions\n       ) \n```\n:::\n\n\n\n\n1.  This function takes the `.data` argument you provided (in your example, the `Data` object)...\n2.  And filter the rows based on the conditions outlined\n3.  You can use any function, predefined or custom, and apply it to `filter()`\n4.  It returns a subset of the whole object, keeping the columns and the data structure intact\n\n**Exercise**: filter for observations that occurred in 2025, only. You can use the `year()` function with the `date` variable to retrieve the year.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Apply function to the data\nM7=filter(M7,year(date)==2025)\n\n#Show the first 10 observations\nhead(M7)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  symbol       date   volume adjusted\n1   AAPL 2025-01-02 55740700   243.85\n2   AAPL 2025-01-03 40244100   243.36\n3   AAPL 2025-01-06 45045600   245.00\n4   AAPL 2025-01-07 40856000   242.21\n5   AAPL 2025-01-08 37628900   242.70\n6   AAPL 2025-01-10 61710900   236.85\n```\n\n\n:::\n:::\n\n\n\n\n## 3. The `arrange()` function\n\nThe `arrange()` function reorders the rows of a data frame by the values of selected columns:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Some Options, always in the following format: the object you are rearranging + the reordering scheme\narrange(.data, variable1) #Ascending by variable_1\narrange(.data, variable1, variable_2) #Ascending by variable_1 and then variable_2\narrange(.data, variable2, variable_1) #Ascending by variable_2 and then variable 1\narrange(.data, variable1, desc(variable_2)) #Ascending by variable_1, and then descending by variable_2\n```\n:::\n\n\n\n\n1.  This function takes the `.data` argument you provided (in your example, the `Data` object)...\n2.  And reorders the rows of your `data.frame` (or `tibble`)\n3.  This can be useful for visualization, but also for applying position-dependent functions, like `lag()`, `lead()`, `head()`, and `tail()`\n\n**Exercise**: arrange the dataset by descending `date` (newest to oldest) and `symbol`..\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Apply function to the data\nM7=arrange(M7,desc(date),symbol)\n\n#Show the first 10 observations\nhead(M7)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  symbol       date    volume adjusted\n1   AAPL 2025-01-29  45486100   239.36\n2   AMZN 2025-01-29  26091700   237.07\n3   GOOG 2025-01-29  12287800   197.18\n4   META 2025-01-29  21377800   676.49\n5   MSFT 2025-01-29  23581400   442.33\n6   NVDA 2025-01-29 467120600   123.70\n```\n\n\n:::\n:::\n\n\n\n\n## 4. The `summarize()` function\n\nThe `summarise()` - or `summarize()` - function creates a new data frame. It returns one row for each combination of grouping variables; if there are no grouping variables, the output will have a single row summarising all observations in the input. It will contain one column for each grouping variable and one column for each of the summary statistics that you have specified.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarize(.data, #The object which you are performing the operations \n       new_variable_1 = mean(var1,na.rm=TRUE), #Average of var1, removing NA values\n       new_variable_2 = median(var2,na.rm=TRUE), #Median of var1, removing, NA values\n       new_variable_3 = n_distinct(var2) #Number of unique values of var2\n       ) \n```\n:::\n\n\n\n\n1.  This function takes the `.data` argument you provided (in your example, the `Data` object)...\n2.  And reshapes the `data.frame` (or `tibble`) by the aggregation functions\n3.  As the name suggests, it is used to summarize a table\n\n**Exercise**: summarize the dataset by creating an `average` column, defined as the average `adjusted` prices. You can use the `mean()` function to get the average. Use the option `na.rm=TRUE` inside the `mean` function to make sure that `NA` values are disregarded.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Apply function to the data\nSummary=summarize(M7,average=mean(adjusted,na.rm=TRUE))\n\n#Show the first observations\nhead(Summary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   average\n1 322.1803\n```\n\n\n:::\n:::\n\n\n\n\n## 5. Slice and dice through `group_by`\n\nThe `group_by()` function takes an existing table and converts it into a *grouped* table where operations are performed \"by group\". Using `ungroup()` removes grouping.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nData=group_by(Data,v1,v2,v3)\nData=summarize(avg=mean(x,na.rm=TRUE))\n```\n:::\n\n\n\n\n1.  This function takes the `.data` argument you provided (in your example, the `Data` object)...\n2.  And creates the `avg` variable taking the average of `x` within each tuple defined by the grouping variables (in this case, `v1`,`v2`, and `v3` )\n3.  It returns a `grouped dataframe`, with the results of `avg` displayed for each unique combination of `v1`,`v2`, and `v3`\n\nThe `group_by()` function in R is part of the dplyr package and is used to create grouped data frames. It is commonly used in combination with `summarize()`, `mutate()`, and other `dplyr` functions to perform operations within groups.\n\n::: callout-alert\n### Important\n\nAfter grouping, it's often necessary to *ungroup* the data to prevent unintended behavior in subsequent operations:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nData=group_by(Data,v1,v2,v3)\nData=summarize(avg=mean(x,na.rm=TRUE))\nData=ungroup(Data)\n```\n:::\n\n\n\n:::\n\nLet's try the latest `summarize()` call again, but now grouping the data by `symbol` first:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Apply function to the data\nM7=group_by(M7,symbol)\nSummary=summarize(M7,average=mean(adjusted,na.rm=TRUE))\n\n#Show the first 10 observations\nhead(Summary,10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 2\n  symbol average\n  <chr>    <dbl>\n1 AAPL      234.\n2 AMZN      227.\n3 GOOG      196.\n4 META      625.\n5 MSFT      430.\n6 NVDA      137.\n7 TSLA      405.\n```\n\n\n:::\n:::\n\n\n\n\n## 6. Pipe your way through the code `%>%`\n\nThe `dplyr` verbs, in isolation, are a great tool for data analysts, but what really makes them to shine is what glues them together. The pipe operator (`%>%` or `|>`) is a key feature of the `magrittr` package (included in the `tidyverse`) and is widely used in R, especially together with `dplyr`, for improving code readability and structuring data transformation workflows. Key benefits include:\n\n✅ Improved Readability – The sequence of transformations is clear.\n\n✅ No Need for Temporary Variables – Each step directly passes its result to the next function.\n\n✅ Avoids Nesting – No deeply nested function calls.\n\nThe pipe operator allows you to pass the result of one function as the first argument to the next function, making code more readable and eliminating the need for nested function calls. To show its functionality in action, in the code chunk below, both parts of the code produce the exact same result, but the latter, using the pipe operator, is much simpler to read:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Instead of \nData = read.csv('Data.csv') #Start with the data\nData = mutate(Data, new_var_1=var_1*10)#Mutate\nData = select(Data, var_1,var_2,new_var_1,where(is.numeric))#Select\nData = filter(Data, new_var_1>5)#Filter\nData = arrange(Data, new_var_1,desc(var2))#Arrange\nData = summarize(Data, new_var=mean(new_var_1,na.rm=TRUE))#Summarize\n\n#Do\nData = read.csv('Data.csv')%>% #Start with the data\n        mutate(new_var_1=var_1*10)%>% #Mutate\n        select(var_1,var_2,new_var_1,where(is.numeric))%>% #Select\n        filter(new_var_1>5)%>% #Filter\n        arrange(new_var_1,desc(var2))%>% #Arrange\n        summarize(new_var=mean(new_var_1,na.rm=TRUE))#Summarize\n```\n:::\n\n\n\n\n## Hands-on Exercise\n\nOn January $25^{th}$, chinese startup *DeepSeek* disrupted the tech stock market as investors reassessed the likely future investment in Artificial Intelligence hardware. As part of your work as a buy-side analyst, you were asked to analyze how the *Magnificent 7* performed after the *DeepSeek*. To this point, follow the instructions and answer to the following question: **which stock suffered the most during January 2025?**\n\n1.  To answer this question, you will be using all `dplyr` verbs you've practiced so far\n2.  Furthermore, you will be also using some common base R and ther `dplyr` functions, like `lag()`, `prod()`, `as.Date()` and `drop_na()`\n\nThe expected result is a `data.frame` object that shows, for each `symbol`, the monthly return on January, 2025, ordered from lowest-to-highest.\n\n::: callout-tip\n### Instructions\n\nThe data, stored in `M7.csv`, can be loaded using `read.csv('M7.csv')`. You can download it using the link shown in *Slide 4*.\n\n1.  Select only the `symbol`, `date`, and `adjusted` columns, and arrange the dataset from oldest to newest\n2.  Mutate your `date` variable, making sure to read it as a Date object using `as.Date()`\n3.  Create a `Year` variable and filter only on observations happening in 2025. You can use the `year()` function to retrieve the year of a given `Date` column.\n4.  Group data by `symbol`\n5.  Create, for each different `symbol`, a `Return` variable that is defined as $P_{t+1}/P_{t}$, where $t$ refers to a date. You can use the `lag()` function for this\n6.  You will see that `lag` produces an `NA` whenever you try to lag the first observation. To make sure your data does not contain any `NA`, call `drop_na()`\n7.  Create, for each different `symbol`, a `Cum_Return` variable that is defined as the cumulative return. Compounded returns over time can be written as $\\small \\prod(1+R_t)=(1+R_1)\\times(1+R_2)\\times...\\times(1+R_t)$. For this, you can use the `prod()` function.\n8.  Pick the latest observation from each `symbol` and arrange the table from lowest-to-highest return. The function `slice_tail(n=x)` retrieves the bottom `x` observations, whereas `slice_head(n=y)` retrieves the top `y`.\n:::\n\n## Solution walkthrough\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Read the Data\nM7%>%\n#Select only the columns of interest\nselect(symbol,date,adjusted)%>%\n#Make sure date is read as a Date object\nmutate(date=as.Date(date))%>%\n#Filter for observations happening in 2025\nfilter(year(date)==2025)%>%\n#Arrange from chronological order\narrange(date)%>%\n#Group by Symbol to perform the calculations\ngroup_by(symbol)%>%\n#Create the return\nmutate(Return = adjusted/lag(adjusted,default = NA))%>%\n#Remove NAs before doing the cumulative product\ndrop_na()%>%\nmutate(Cum_Return = cumprod(Return)-1)%>%\n#Select the latest observation from each symbol\nslice_tail(n=1)%>%\n#Select symbol, date, and cumulative return\nselect(symbol,date,Cum_Return)%>%\n#Arrange from lowest-to-highest\narrange(Cum_Return)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 3\n# Groups:   symbol [7]\n  symbol date       Cum_Return\n  <chr>  <date>          <dbl>\n1 NVDA   2025-01-29    -0.106 \n2 AAPL   2025-01-29    -0.0184\n3 TSLA   2025-01-29     0.0259\n4 GOOG   2025-01-29     0.0344\n5 MSFT   2025-01-29     0.0567\n6 AMZN   2025-01-29     0.0765\n7 META   2025-01-29     0.129 \n```\n\n\n:::\n:::\n\n\n\n\nThis code processes stock price data from `M7` using the `dplyr` package. It calculates the cumulative return for each stock (`symbol`) in the year 2025, then selects the latest available observation per stock and sorts them from lowest to highest cumulative return.\n\n1.  **Read the Data.** `M7` is assumed to be a data frame or tibble containing stock data ready in your session. You can use `read.csv()` and store it in an R object. The pipe operator `%>%`) is used to chain functions together.\n\n2.  **Select Relevant Columns.** Keeps only the relevant columns for the analysis:\n\n-   `symbol` → The stock ticker\n-   `date` → The trading date\n-   `adjusted` → The adjusted closing price (used for return calculations)\n\nMaking sure the `select` function is applied as one of the first adjustments can facilitate data wrangling as it shrinks the dataset for the upcoming operations.\n\n3.  **Ensure `date` is a `Date` object in your session**. The code converts the `date` column to a `Date` object to enable time-based filtering and calculations, like `year()`.\n\n4.  **Filter Data for 2025**. The code uses `year(date) == 2025` (from the `lubridate` package, loaded together with the `tidyverse`) to keep only data from 2025.\n\n5.  **Sort Data in Chronological Order**. The code ensures that stock prices are arranged earliest to latest for correct return calculations.\n\n6.  **Groups the dataset by stock (`symbol`)**. Using `group_by()` ensures that return calculations are performed for each stock separately\n\n7.  **Calculate Daily Returns**. After the dataset is grouped, we use the `mutate()` function to create our return metric:\n\n$$\nReturn=\\dfrac{P_{t}}{P_{t-1}}\n$$\n\n-   Uses `lag(adjusted)` to get the previous day's adjusted price.\n-   The first row in each group will have NA (because there's no previous price)\n\nBecause of that, we also need a call to `drop_na()` to make sure that whenever we are multiplying these indices, we are not including `NA` values.\n\n::: callout-important\n### Important\n\nThe function `cumprod()`, which calculates the cumulative product of a series, multiplies values sequentially. However, if there are missing values (`NA`) in the sequence, `cumprod()` propagates `NA` to all subsequent values. This can corrupt the entire computation.\n\nFor example, ommitting the `drop_na()` step in the solution code would produce `NA` all over `Cum_Return`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Read the Data\nM7%>%\n#Select only the columns of interest\nselect(symbol,date,adjusted)%>%\n#Make sure date is read as a Date object\nmutate(date=as.Date(date))%>%\n#Filter for observations happening in 2025\nfilter(year(date)==2025)%>%\n#Arrange from chronological order\narrange(date)%>%\n#Group by Symbol to perform the calculations\ngroup_by(symbol)%>%\n#Create the return\nmutate(Return = adjusted/lag(adjusted,default = NA))%>%\n#Remove NAs before doing the cumulative product\nmutate(Cum_Return = cumprod(Return)-1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 126 × 5\n# Groups:   symbol [7]\n   symbol date       adjusted Return Cum_Return\n   <chr>  <date>        <dbl>  <dbl>      <dbl>\n 1 AAPL   2025-01-02     244. NA             NA\n 2 AMZN   2025-01-02     220. NA             NA\n 3 GOOG   2025-01-02     191. NA             NA\n 4 META   2025-01-02     599. NA             NA\n 5 MSFT   2025-01-02     419. NA             NA\n 6 NVDA   2025-01-02     138. NA             NA\n 7 TSLA   2025-01-02     379. NA             NA\n 8 AAPL   2025-01-03     243.  0.998         NA\n 9 AMZN   2025-01-03     224.  1.02          NA\n10 GOOG   2025-01-03     193.  1.01          NA\n# ℹ 116 more rows\n```\n\n\n:::\n:::\n\n\n\n:::\n\n8.  **Calculate Cumulative Returns**. With the series of daily returns in place cumulative return over time can be retrieved by compounding each individual return over time:\n\n$$\n\\text{Cumulative Return}_{t=1\\rightarrow T}= (1+R_1)\\times(1+R_2)\\times(1+R_3)\\times...\\times(1+R_t)\\equiv\\prod_{t=1}^{T}(1+R_t)\n$$ To perform such calculations, the code uses `cumprod(Return)`, which multiplies returns over time. In the end, we also need to subtract 1 to express it as a percentage return.\n\n9.  **Select the Latest Observation Per Stock**. The `slice_tail()` function keeps only the last row (i.e., the most recent date) for each stock. Note that this behavior is only possible because our data has been grouped by `symbol` in the subsequent steps. In an `ungrouped` case, `slice_tail()` would retrieve the latest observation considering the data as a whole - in this case, META cumulative returns.\n\n10. **Keep Only Key Columns and Rearrange**. After we're done creating the relevant variables, we can use the `select()` function to keep only the columns that are of interest: `symbol`,`date`, and `Cum_Return`, and use the `arrange()` function to sort observations by ascending order of cumulative returns (*i.e*, lowest-to-highest).\n\n## Try doing some edits on your own!\n\nTry thinking about changes you could do to either improve code readability of the analysis. A couple of edits that can be made include, but are not limited, to:\n\n1.  Adding more time periods to the analysis\n2.  Increasing the set of `assets` to include more tech firms other than the magnificent seven\n3.  Calculate volatility metrics using `var()` or `stdev()` functions\n\nPlay around with these concepts to get familiar with all the data manipulation tools that come with `dplyr`!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}