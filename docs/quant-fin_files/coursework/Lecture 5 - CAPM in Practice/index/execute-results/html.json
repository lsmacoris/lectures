{
  "hash": "e2ab0e6659369e3b810dd7a572bfac9f",
  "result": {
    "engine": "knitr",
    "markdown": "---\n#title: \"Risk and Return\"\nauthor: \"Lucas S. Macoris\"\nformat:\n  revealjs:\n    title: 'The Capital Asset Pricing Model (CAPM) in practice'\n    theme: [default, ../~ Metadata/custom.scss]\n    auto-stretch: false\n    author: 'Lucas S. Macoris'\n    logo: 'Images/logo.jpg'\n    footer: \"[@ Website](https://lsmacoris.github.io/) | [@ Slides](https://lsmacoris.github.io/lectures/quant-fin) | [@ Office-hour appointments](https://calendly.com/lucas-macoris-fgv/appointment-lsm)\"\n    toc: false\n    cls: ../~ Metadata/abntex2.cls\n    incremental: false\n    bibliography: '../~ Metadata/Bibliography.bib'\n    slide-number: true\n    show-slide-number: all\n    transition: slide\n    background-transition: fade\n    chalkboard: true\n    width: 1600\n    height: 900\n    smaller: false\n    \neditor: visual\nfrom: markdown+emoji\n---\n\n\n\n## Outline\n\n-   This lecture is mainly based the following textbooks:\n    1.  *Tidy Finance* [@tidyfinance]\n    2.  *R for Data Science* [@r4ds]\n\n::: callout-note\n### Coding Replications\n\nFor coding replications, whenever applicable, please follow [this](https://lsmacoris.github.io/lectures/quant-fin.html) page or hover on the specific slides with containing coding chunks.\n\n1.  Ensure that you have your [{{<fa brands r-project>}}]{.blue} session properly set-up according to the instructions outlined in the course webpage\n2.  In the webpage, you can also find a detailed discussion of the examples covered in this lecture\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\n## Disclaimer\n\n::: callout-important\n### Disclaimer\n\nThe information presented in this lecture is for educational and informational purposes only and should not be construed as investment advice. Nothing discussed constitutes a recommendation to buy, sell, or hold any financial instrument or security. Investment decisions should be made based on individual research and consultation with a qualified financial professional. The presenter assumes no responsibility for any financial decisions made based on this content.\n\nAll code used in this lecture is publicly available and is also shared on my [GitHub](https://github.com/lsmacoris) page. Participants are encouraged to review, modify, and use the code for their own learning and research purposes. However, no guarantees are made regarding the accuracy, completeness, or suitability of the code for any specific application.\n\nFor any questions or concerns, please feel free to reach out via email at [lucas.macoris\\@fgv.br](mailto:lucas.macoris@fgv.br)\n:::\n\n## Background\n\n-   The [*Capital Asset Pricing Model (CAPM)*]{.blue} is a very practical, robust and straightforward implementation for modeling expected returns\n\n-   It gets managers to think about risk in the correct way: instead of thinking about total risk, the [CAPM]{.blue} shows us that we only the market risk (non-diversifiable) should be the concern\n\n. . .\n\n-   There are [three]{.blue} simplifying assumptions around investor behavior that the [CAPM]{.blue} establishes:\n\n::: callout-tip\n### The Capital Asset Pricing Model (CAPM) Assumptions\n\n1.  Investors can buy and sell all securities at competitive market prices without incurring taxes or transactions costs can borrow and lend at the risk-free interest rate\n\n2.  Investors hold only efficient portfolios of traded securities\n\n3.  Investors have homogeneous expectations regarding the volatilities, correlations, and expected returns of securities\n:::\n\n. . .\n\n**Question**: why these assumptions are important?\n\n## Pricing the Risk Premium under the CAPM\n\n-   Recall that the expected return of any given asset $i$ is given by:\n\n$$\n\\small E[R_i]  =  R_f + \\beta_i^P  \\times (E[R_p] - R_f)\n$$\n\n-   How can we find $\\beta_i^P$, the sensitivity of asset $i$ returns to the efficient portfolio, $P$?\n    1.  To identify the efficient portfolio [@Markowitz], we need to know the expected returns, volatilities, and correlations between all available investments!\n    2.  However, if the [CAPM]{.blue} assumptions are valid, we can now identify the efficient portfolio: **it is equal to the market portfolio!**\n-   What does that mean for us in terms of determining expected equity returns? Until now, we were agnostic on what $P$ was. Under the [CAPM]{.blue}, we can change the subscript $P$ to $M$:\n\n$$\n\\small E[R_i] =  R_f + \\beta_i^M  \\times (E[R_m] - R_f)\n$$\n\n## CAPM Implication 1: the Capital Market Line (CML)\n\n![](Images/F1.png){fig-align=\"center\" width=\"70%\"}\n\n## The CML shows no clear relationship between risk and return...\n\n![](Images/F2.png){fig-align=\"center\" width=\"70%\"}\n\n## CAPM Implication 2: the Security Market Line (SML) makes the relationship clear when focusing only ($\\beta^M_i$)!\n\n![](Images/F3.png){fig-align=\"center\" width=\"60%\"}\n\n## Hands-On Exercise\n\n-   You work as a buy-side analyst at *Pierpoint Capital*, focusing on the chemicals industry. You job is replicate the [CAPM]{.blue} for a handful of securities from the Chemical (basic) industry and provide insights for the fund manager:\n\n1.  Which stocks, according to the [CAPM]{.blue}, are [undervalued]{.green} and why?\n2.  Which stocks, according to the [CAPM]{.blue}, are [overvalued]{.red} and why?\n3.  If the fund were to implement your strategy, what are the risks associated with?\n\n::: callout-important\n### Specific Instructions\n\n1.  The securities to be included in the analysis are: Dow (ticker: *DOW*), LyondellBasell (*LYB*), Perimeter (*PRM*), Flotek (*FTK*), Rayonier (*RYAM*), Albemarle (*ALB*), Celanese (*CE*),The Chemours (*CC*), Ginkgo Bioworks (*DNA*), and American Vanguard (*AVD*).\n\n2.  CAPM estimation should be done at a *weekly* level using data from 2024\n:::\n\n## Estimating the Equity Cost of Capital in practice\n\n-   The dynamics behind the pricing of securities under the [CAPM]{.blue} are:\n\n$$R_i = R_f + \\beta \\times (E[R_m] - R_f)$$\n\n-   However, no one really told you from where the numbers came from\n\n-   Recall that, under the [CAPM]{.blue}, we need to have estimates related to the market portfolio:\n\n    1.  It is is equal to the risk-free interest rate, [$R_f$]{.blue}...\n    2.  The expected return on the market portfolio, [$E[R_m]$]{.blue}...\n    3.  And a stock's s sensitivity to the market portfolio, denoted by [$\\beta$]{.blue}\n\n## Cost of Equity Components: the risk-free rate\n\n-   The first ingredient of CAPM is [risk-free rate]{.blue}, which is the interest rate that investors can earn while having zero to limited volatility\n\n-   Suggestions on how to pick the Risk-Free ($R_f$) rate to be used:\n\n    1.  The yield on U.S. Treasury securities\n    2.  Surveys suggest most practitioners use 10- to 30-year treasuries\n    3.  Highest quality assets\n\n-   Often, we use a short-term risk-free rate to evaluate a short-term investment, and a long-term rate when evaluating a long-term investment\n\n::: callout-important\n### Country-specific risk-free rates\n\nWhenever modeling assets *outside* of the U.S, we can either use the yields for local treasuries (*i.e*, relatively safer assets) or use U.S treasuries by adjusting the calculations for country-specific risk premium - see, for example, Brazilian's *EMBI*.\n:::\n\n## Cost of Equity Components: the market risk premium\n\n-   Another component of the Cost of Equity is the difference between $E[R_m]$ and $R_f$ (the market risk premium)\n\n-   Ways to estimate the market risk premium:\n\n    1.  Estimate the risk premium ($E[R_m] − R_f$) using the historical average excess return of the market over the risk-free interest rate\n    2.  Notice that, even with long periods, we often have large standard errors\n    3.  Implicitly, you are assuming that the past is a good proxy for the future\n\n::: callout-important\n### Watch-out!\n\nIndexes like the [S&P500]{.blue} and [Ibovespa]{.blue} are not considered the [market portfolio]{.blue}, but rather, they are *proxies* for the market portfolios - in other words, they are reasonable approximations of the market portfolio for a given set universe of securities\n:::\n\n## Step 1: Collecting Data\n\n-   As a suggestion, we will be collecting data on U.S. Treasury yields and Market Risk Premium using [Kenneth French]{.blue}'s [website](https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html), which hosts a data library with updated on U.S. returns from a wide varieaty of risk factors and asset classes\n\n    1.  Treasury yields ($R_F$) are defined as the daily returns on the *1-month Treasury Bill*\n    2.  Market Returns ($R_M$) are defined as the value-weighted returns on a bundle of U.S. stocks [^1]\n\n-   I have already worked on the data for you, and you can download it using the *Download* button - details on the code used to manipulate the data and put it into tidy format are presented in the next slide\n\n-   To load the data in your session, call:\n\n[^1]: Click [here](https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/Data_Library/f-f_5_factors_2x3.html) for details around the stock selection criteria.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Assuming that you have the file in your working directory\nFF_Data=readRDS('FF_Data.RDS')\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<button class=\"btn btn-default\" onclick=\"&#10;    async function downloadFile(event) {&#10;      event.preventDefault();&#10;      try {&#10;        const response = await fetch(&#39;data:application/octet-stream;base64,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&#39;);&#10;        if (!response.ok) throw new Error(&#39;Network response failed&#39;);&#10;        const blob = await response.blob();&#10;        const blobUrl = window.URL.createObjectURL(blob);&#10;        const a = document.createElement(&#39;a&#39;);&#10;        a.href = blobUrl;&#10;        a.download = &#39;FF_Data.rds&#39;;&#10;        a.style.display = &#39;none&#39;;&#10;        document.body.appendChild(a);&#10;        a.dispatchEvent(new MouseEvent(&#39;click&#39;));&#10;        document.body.removeChild(a);&#10;        setTimeout(() =&gt; {&#10;          window.URL.revokeObjectURL(blobUrl);&#10;        }, 100);&#10;        return false;&#10;      } catch (error) {&#10;        console.error(&#39;Download failed:&#39;, error);&#10;        alert(&#39;Download failed. Please try again.&#39;);&#10;      }&#10;    }&#10;    downloadFile(event);&#10;  \" has_icon=\"TRUE\"><i class=\"fa fa-save\"></i> Download Raw data</button>\n```\n\n:::\n:::\n\n\n\n## Step 1: $R_M$, $R_F$, and the Market Risk Premium\n\n::: panel-tabset\n## Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Use Fama-French Data to retrieve Rf and MRP\nFF_url <- \"https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_5_Factors_2x3_daily_CSV.zip\"\ntemp_file <- tempfile()\ndownload.file(FF_url, temp_file)\n\n#Download and manipulate the data\nunzip(temp_file)%>%\nread.csv(skip=3)%>%\n#Select only the data, Excess Returns, and Risk-Free Columns\nselect(1,2,7)%>%\n#Change the names of the variables\nsetNames(c('Date','MRP','Rf'))%>%\n#Make sure the date columns is read as a Date object\nmutate(Date=as.Date(strptime(Date,format='%Y%m%d')))%>%\n#Filter for 2024\nfilter(year(Date)==2024)%>%\n#Manipulate data to aggregate\nmutate(across(where(is.numeric),\\(x) (1+x/100)))%>%\n#Pivot to get only one column\npivot_longer(names_to = \"Key\",values_to = \"Value\",-Date)%>%\n#Group by the newly created Key column\ngroup_by(Key)%>%\n#Apply nest() for functional programming and perform aggregation\nnest()%>%\nmutate(data = map(data,as.xts))%>%\nmutate(data = map(data,apply.weekly,\\(x) prod(x)-1))%>%\nmutate(data = map(data,as.data.frame))%>%\nmutate(data = map(data,~rownames_to_column(.,'Date')))%>%\nunnest(data)%>%\n#Pivot back to wide format\npivot_wider(names_from = Key,values_from = Value)%>%\n#Write as a csv\nsaveRDS('MRP_and_RF.rds')\n```\n:::\n\n\n\n## Output\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n         Date           MRP           Rf\n1  2024-01-05 -1.880351e-02 0.0008802904\n2  2024-01-12  1.630595e-02 0.0011004841\n3  2024-01-19  9.912377e-03 0.0008802904\n4  2024-01-26  1.043348e-02 0.0011004841\n5  2024-02-02  1.185523e-02 0.0010804666\n6  2024-02-09  1.484388e-02 0.0010504411\n7  2024-02-16 -2.926148e-03 0.0010504411\n8  2024-02-23  1.254919e-02 0.0008402646\n9  2024-03-01  1.060239e-02 0.0010504411\n10 2024-03-08 -3.840512e-03 0.0010504411\n11 2024-03-15 -3.377924e-03 0.0010504411\n12 2024-03-22  2.306942e-02 0.0010504411\n13 2024-03-28  4.564621e-03 0.0008402646\n14 2024-04-05 -1.150557e-02 0.0010504411\n15 2024-04-12 -1.675444e-02 0.0010504411\n16 2024-04-19 -3.211752e-02 0.0010504411\n17 2024-04-26  2.707724e-02 0.0010504411\n18 2024-05-03  5.745092e-03 0.0010204162\n19 2024-05-10  1.656236e-02 0.0010004001\n20 2024-05-17  1.543225e-02 0.0010004001\n21 2024-05-24 -1.968430e-03 0.0010004001\n22 2024-05-31 -6.544949e-03 0.0008002400\n23 2024-06-07  9.163612e-03 0.0011004841\n24 2024-06-14  1.293156e-02 0.0011004841\n25 2024-06-21  5.376481e-03 0.0008802904\n26 2024-06-28  8.368114e-05 0.0011004841\n27 2024-07-05  1.761172e-02 0.0008402646\n28 2024-07-12  1.057404e-02 0.0010504411\n29 2024-07-19 -1.923631e-02 0.0010504411\n30 2024-07-26 -6.090287e-03 0.0010504411\n31 2024-08-02 -2.779540e-02 0.0010704580\n32 2024-08-09 -1.139424e-03 0.0011004841\n33 2024-08-16  3.955583e-02 0.0011004841\n34 2024-08-23  1.501644e-02 0.0011004841\n35 2024-08-30  9.239343e-04 0.0011004841\n36 2024-09-06 -4.546808e-02 0.0008002400\n37 2024-09-13  4.114533e-02 0.0010004001\n38 2024-09-20  1.494732e-02 0.0010004001\n39 2024-09-27  4.994023e-03 0.0010004001\n40 2024-10-04  1.992034e-03 0.0008803095\n41 2024-10-11  1.142536e-02 0.0008502890\n42 2024-10-18  8.262229e-03 0.0008502890\n43 2024-10-25 -1.139132e-02 0.0008502890\n44 2024-11-01 -1.142076e-02 0.0008803095\n45 2024-11-08  5.133601e-02 0.0010004001\n46 2024-11-15 -2.267490e-02 0.0010004001\n47 2024-11-22  2.167504e-02 0.0010004001\n48 2024-11-29  9.707892e-03 0.0008002400\n49 2024-12-06  1.021493e-02 0.0008502890\n50 2024-12-13 -9.249021e-03 0.0008502890\n51 2024-12-20 -2.273584e-02 0.0008502890\n52 2024-12-27  5.566751e-03 0.0006801734\n53 2024-12-31 -1.544986e-02 0.0003400289\n```\n\n\n:::\n:::\n\n\n:::\n\n## Step 2: collecting stock price information\n\n-   Now that we have the right-hand side components of your [CAPM]{.blue} equation, it is time to collect information on stock prices for the selected stocks. By now, you can pretty much apply the rationale you've done in previous lectures:\n\n    1.  Create a vector `assets` containing the tickers that you wish to request information from\n    2.  Create a `start` and `end` objects containing the analysis period\n    3.  Use `tq_get()` and pipe `assets` onto the function along with `from=start` and `to=end` arguments\n    4.  Manipulate the data to calculate weekly returns, assigning it to an object called `Stock_Data`\n\n-   Finally, you can use `left_join()` to merge `Stock_Data` with `FF_Data`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nFinal_Data=Stock_Data%>%left_join(FF_Data)\n```\n:::\n\n\n\n## Step 2: collecting stock price information\n\n::: panel-tabset\n## Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Create the start and end dates\nstart=as.Date('2024-01-01')\nend=as.Date('2024-12-31')\n\n#Create the list of assets\nassets=c('DOW','LYB','PRM','FTK','RYAM',\n         'ALB','CE','CC','DNA','AVD')\n\n#Collect data, select necessary columns, and calculate weekly returns\nStock_Data=assets%>%\n  tq_get(from=start,to=end)%>%\n  select(symbol,date,adjusted)%>%\n  group_by(symbol)%>%\n  tq_transmute(select = adjusted,\n               mutate_fun = weeklyReturn,\n               col_rename = 'weekly_return')\n\n#Left join when column names are different\nFull_Data=Stock_Data%>%left_join(FF_Data,by=c('date'='Date'))\n```\n:::\n\n\n\n## Output\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 530 × 5\n# Groups:   symbol [10]\n   symbol date       weekly_return      MRP       Rf\n   <chr>  <date>             <dbl>    <dbl>    <dbl>\n 1 DOW    2024-01-05      -0.00922 -0.0188  0.000880\n 2 DOW    2024-01-12      -0.0265   0.0163  0.00110 \n 3 DOW    2024-01-19      -0.0105   0.00991 0.000880\n 4 DOW    2024-01-26       0.0237   0.0104  0.00110 \n 5 DOW    2024-02-02      -0.0118   0.0119  0.00108 \n 6 DOW    2024-02-09       0.0107   0.0148  0.00105 \n 7 DOW    2024-02-16       0.0276  -0.00293 0.00105 \n 8 DOW    2024-02-23       0.0164   0.0125  0.000840\n 9 DOW    2024-03-01       0.00146  0.0106  0.00105 \n10 DOW    2024-03-08       0.0151  -0.00384 0.00105 \n# ℹ 520 more rows\n```\n\n\n:::\n:::\n\n\n\n$\\rightarrow$ *You now have the weekly returns for all selected stocks, the weekly risk-free returns, and the weekly market returns!*\n:::\n\n## Cost of Equity Components: $\\beta$ estimation\n\n-   All that's left is to estimate the stocks's sensitivity to the returns of the market portfolio, $\\beta$\n\n-   From what we know on the theory on portfolio returns, a new asset $i$ should be enhance the performance of a portfolio if:\n\n$$\n\\small \\underbrace{\\frac{E[R_i] - R_f}{\\sigma_{i} \\times Corr(R_i,R_m)}}_{\\text{Sharpe Ratio of } i} > \\underbrace{\\frac{E[R_m] - R_f}{\\sigma_{m}}}_{\\text{Sharpe Ratio of Market}}\n$$\n\n-   With that, we saw that the expected return from an asset $i$ should be:\n\n$$\n\\small R_i - R_f = \\underbrace{\\frac{\\sigma_{i} \\times Corr(R_i,R_m)}{\\sigma_{m}}}_{\\beta^M_i}  \\times (E[R_m] - R_f)\n$$\n\n## Cost of Equity Components: $\\beta$ estimation, continued\n\n-   Because $\\small Corr(R_i,R_m)=\\frac{Cov(R_i,R_m)}{\\sigma_i\\sigma_m}$, we have that:\n\n$$\n\\small (R_i - R_f)=\\frac{\\sigma_{i} \\times Cov(R_i,R_m)}{\\sigma_i \\sigma_m\\sigma_{m}}  \\times (E[R_p] - R_f)\\rightarrow  (R_i - R_f)=  \\underbrace{\\frac{Cov(R_i,R_m)}{\\sigma^2_m}}_{\\text{OLS formula for slope}}\\times (E[R_p] - R_f)\n$$\n\n-   We can then estimate $\\beta$ using an *Ordinary Least Squares* regression:\n\n$$\n\\small \\underbrace{(R_i - R_f)}_{\\text{Excess Return}} = \\underbrace{\\alpha_i}_{\\text{Uncorrelated Return}} + \\underbrace{\\beta_i}_{\\text{Stock's Market Sensitivity}} \\times \\underbrace{(R_m - R_f)}_{\\text{Risk Premium}} + \\epsilon_i\n$$\n\n-   $\\epsilon_i$ is the error term (or the *residual*). It represents the *deviations* from the best-fitting line and is, by definition, zero on average (or else we could improve the fit), and represent firm-specific risk that is diversifiable and that averages out in a large portfolio\n\n## Step 3: estimating $\\alpha$ and $\\beta$\n\n-   We know need estimate the following equation for each stock in our analysis:\n\n$$\n\\small Excess_t = \\alpha + \\beta \\times (R_m - R_f) + \\epsilon_t\n$$\n\n-   The naivest way to do it is to repeat the process $10$ times, filtering each stock at a time, and running an *OLS* model with the `lm()` function:\n\n    1.  Start with the `Full_Data` object and pipe onto `mutate` to creat the `excess_return` variable\n    2.  `select` only the `symbol`, the `excess_return`, and the `MRP` columns\n    3.  Use `filter` to work with a single ticker, say, `symbol=='DOW'`\n    4.  Call the `lm()` function to run an *OLS* regression of excess returns on market returns\n\n-   The next slide shows the result of estimating the [CAPM]{.blue} model for *RYAM*\n\n## Step 3: estimating $\\alpha$ and $\\beta$ (*RYAM* only)\n\n::: panel-tabset\n## Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Manipulate data\nRYAM=Full_Data%>%\n  filter(symbol=='RYAM')%>%\n  mutate(excess_return=weekly_return-Rf)%>%\n  select(symbol,excess_return,MRP)\n\n#Run the OLS regression\nOLS=lm(excess_return~MRP,data=RYAM)\n\n#Inspect the results using summary()\nsummary(OLS)\n```\n:::\n\n\n\n## Output\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = excess_return ~ MRP, data = RYAM)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.153351 -0.036530 -0.005546  0.026486  0.185118 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept) 0.008144   0.009698   0.840   0.4050  \nMRP         1.237611   0.529959   2.335   0.0236 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06842 on 50 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.09835,\tAdjusted R-squared:  0.08031 \nF-statistic: 5.454 on 1 and 50 DF,  p-value: 0.02358\n```\n\n\n:::\n:::\n\n\n:::\n\n## Understanding the $\\beta$ term inside the OLS estimation\n\n$$\n\\small \\underbrace{(R_i - R_f)}_{\\text{Excess Return}} = \\underbrace{\\alpha}_{\\text{Uncorrelated Return}} + \\underbrace{\\beta}_{\\text{Stock's Market Sensitivity}} \\times \\underbrace{(R_m - R_f)}_{\\text{Risk Premium}} + \\epsilon\n$$\n\n1.  $\\beta$ is the sensitivity to market risk. It measures the historical variation of the security relative to the market\n\n2.  According to the CAPM, all assets should line on the *Security Market Line (SML)*\n\n-   If $\\beta>1$, it means that a 1% variation in market returns implies a variation that is [greater]{.blue} than 1% in stock returns (either [up]{.green} or [down]{.red}!)\n-   If $\\beta<1$ it means that a 1% variation in market returns implies a variation that is [less]{.blue} than 1% in stock returns (either [up]{.green} or [down]{.red}!)\n\n## Assessing Required Returns\n\n-   Suppose you need to price the long-run required returns for investing in an opportunity that has the same equity risk and as *RYAM*. It is now a straightforward application of the [CAPM]{.blue}:\n\n$$\n\\small \\text{Required Return} = R_f +  \\beta \\times (R_m - R_f)\n$$\n\n-   Say, for example that you have the following information:\n\n    1.  The historical long-run risk-free rate return, $\\small R_f$, is $\\small 4.50\\%$\n    2.  The historical long-run market return, $\\small R_m$, is $\\small 9.94\\%$\n    3.  The $\\beta$ you've just found is $\\small 1.23$\n\n-   Then, the long-run required return is simply:\n\n$$\n\\small \\text{Required Return} = 4.5\\%+ 1.23\\times(9.94\\%-4.5\\%)=11.20\\%\n$$\n\n## The Dynamic Nature of $\\beta$\n\n-   In our previous example, $\\beta$ was estimated using a simple *OLS* regression of asset excess returns on market excess returns\n\n-   Our estimate of $\\beta$ was then used to build the required return for *RYAM*. Note, however, that the sensitivity of *RYAM* to systematic risk changes over time:\n\n    1.  Shifts in business models (*e.g.*, firms diversifying revenue streams)\n    2.  Macroeconomic conditions (*e.g.*, monetary policy, recessions)\n    3.  Market structure changes (*e.g.*, sector rotations, liquidity shifts)\n    4.  Leverage variations (*e.g*., debt levels affecting risk exposure)\n\n-   In what follows, we'll look how the $\\beta$ estimate for *RYAM* changes over time considering an estimation window of $24$ weeks\n\n## The Dynamic Nature of $\\beta$, continued\n\n::: panel-tabset\n### Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Manipulate data\nRYAM=Full_Data%>%\n  filter(symbol=='RYAM')%>%\n  mutate(excess_return=weekly_return-Rf)%>%\n  select(date,symbol,excess_return,MRP)\n\n#Create a custom OLS function that extracts all coefficients to pass it to tq_transmute \ncustom_OLS <- function(data) {\n    coef(lm(excess_return ~ MRP, data = data))\n}\n\n#Apply the custom function to tq_transmute in rolling format\nrolling_regs=RYAM%>%\n  tq_transmute(\n      mutate_fun = rollapply,\n      by.column=FALSE,\n      width=24, #Use latest 24 weeks\n      FUN = custom_OLS,\n      col_rename = c('alpha','beta'))%>%\n  filter(!is.na(alpha))\n```\n:::\n\n\n\n### Output\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 30 × 4\n# Groups:   symbol [1]\n   symbol date         alpha     beta\n   <chr>  <date>       <dbl>    <dbl>\n 1 RYAM   2024-06-14 0.0122   0.274  \n 2 RYAM   2024-06-21 0.0110   0.311  \n 3 RYAM   2024-06-28 0.0106   0.510  \n 4 RYAM   2024-07-05 0.00960  0.387  \n 5 RYAM   2024-07-12 0.00884  0.358  \n 6 RYAM   2024-07-19 0.0122   0.00874\n 7 RYAM   2024-07-26 0.0151  -0.186  \n 8 RYAM   2024-08-02 0.0117   0.254  \n 9 RYAM   2024-08-09 0.0222   0.334  \n10 RYAM   2024-08-16 0.0288   0.615  \n# ℹ 20 more rows\n```\n\n\n:::\n:::\n\n\n:::\n\n## The Dynamic Nature of $\\beta$, practice\n\n::: panel-tabset\n### Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Pipe the rolling regression object into ggplot\nrolling_regs%>%\n  ggplot(aes(x=date,y=beta))+\n  geom_line()+\n  geom_smooth()+\n  #Annotations\n  labs(title='Rolling Beta regression (RYAM)',\n       subtitle = 'Source: Yahoo! Finance. Using the latest 24 observations of weekly returns.',\n       x = 'Week',\n       y = 'Estimated Beta')+\n  #Theme\n  theme_minimal()+\n  #Scale x\n  scale_x_date(date_breaks = '4 weeks')+  \n  #Adding further customizations\n  theme(legend.position='none',\n        axis.title.y = element_text(vjust=+4,face='bold'),\n        axis.title.x = element_text(vjust=-3,face='bold'),\n        axis.text = element_text(size=8))\n```\n:::\n\n\n\n### Output\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-14-1.png){width=1440}\n:::\n:::\n\n\n:::\n\n## Understanding the $\\alpha$ term inside the OLS estimation\n\n$$\n\\small \\underbrace{(R_i - R_f)}_{\\text{Excess Return}} = \\underbrace{\\alpha}_{\\text{Uncorrelated Return}} + \\underbrace{\\beta}_{\\text{Stock's Market Sensitivity}} \\times \\underbrace{(R_m - R_f)}_{\\text{Risk Premium}} + \\epsilon\n$$\n\n1.  $\\alpha_i$ is the constant term. It measures the historical performance of the security relative to the expected return predicted by the security market line\n\n2.  It is the distance that the stock’s average return is above or below the SML. Thus, we can say $\\alpha_i$ is a risk-adjusted measure of the stock’s historical performance.\n\n3.  According to the CAPM, $\\alpha_i$ [should not be significantly different from zero]{.blue}\n\n-   If $\\alpha>0$ consistently, it would mean that a security delivers a *constant* positive return and, by definition, independent from the market returns\n-   If that is the case, investors would buy the security up to a point where price adjusts so that $\\alpha$ goes to zero (recall *Assumption #1*)!\n\n## Interpreting $\\alpha$\n\n$$\\small \\alpha_i = \\underbrace{E[R_i]}_{\\text{Observed by the analyst}} - \\underbrace{R_i}_{\\text{Implied by the CAPM}}$$\n\n1.  **A [positive]{.green} alpha means that the stock is [above]{.green} the SML**\n    -   In words, the expected return is [higher]{.green} than its required return. Before prices adjust, investors will anticipate that the price will [rise]{.green} and will likely put in buy orders at the current prices\n2.  **A [negative]{.red} alpha means that the stock is [below]{.red} the SML**\n    -   The expected return is [lower]{.red} than its required return. Before prices adjust, investors will anticipate that the price will [fall]{.red} and will likely put in sell orders at the current prices\n\n$\\rightarrow$ *In either case, we'll be able to improve portfolio results. However, as we do so, prices will change and their alphas will shrink towards zero!*\n\n## Step 4: putting all together\n\n-   Our final step is to use the [CAPM]{.blue} to assess which stocks are [overvalued]{.red}, and which ones are [undervalued]{.green}\n\n-   You could proceed by doing the same procedure as before, but now focusing on the $\\alpha$ term that has been estimated for you\n\n    1.  To do that for all 10 stocks, you could do a `for` loop, store the results, and analyze\n\n    2.  In general, `for` loops are *inefficient*: they run sequentially, have slower performance, and are difficult to read\n\n-   An alternative is to use the `tidyverse` excellent capabilities for functional programming using the `map` function from the `purrr` package, which breaks the problem into sub-pieces and estimate the models in parallel\n\n-   For detailed information on functional programming, see `purrr` documentation [here](https://purrr.tidyverse.org/)\n\n## Step 4: putting all together, continued\n\n::: panel-tabset\n## For Loop\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Start an empty data.frame\nStored_Data=data.frame()\n\nfor (i in assets){\n  \n  #Manipulate data\n  Filtered_Data=Full_Data%>%\n    #Filter for the specific ticker\n    filter(symbol== i)%>%\n    mutate(excess_return=weekly_return-Rf)%>%\n    select(symbol,excess_return,MRP)\n  \n  #Run the OLS regression\n  OLS=lm(excess_return~MRP,data=Filtered_Data)\n\n  #Get the coefficients using the coefficients() function and add it to a temp data\n  \n  Temp_Data = data.frame(ticker=i,\n                         alpha=coefficients(OLS)[1],\n                         beta=coefficients(OLS)[2])\n  \n  #Bind it to the dataframe\n  Stored_Data=Stored_Data%>%rbind(Temp_Data)\n  \n  }\n```\n:::\n\n\n\n## Functional Programming\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCAPM_Estimation=Full_Data%>%\n  mutate(excess_return=weekly_return-Rf)%>%\n  select(symbol,excess_return,MRP)%>%\n  group_by(symbol)%>%\n  nest()%>%\n  mutate(CAPM = map(data,~ lm(excess_return~MRP,data=.)))%>%\n  mutate(coefficients = map(CAPM,tidy))\n```\n:::\n\n\n:::\n\n## Charting the result\n\n::: panel-tabset\n## Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCAPM_Estimation%>%\n  select(coefficients)%>%\n  unnest()%>%\n  filter(term=='(Intercept)')%>%\n  select(symbol,estimate)%>%\n  setNames(c('Ticker','Alpha'))%>%\n  ggplot(aes(x=Ticker,y=Alpha))+\n  geom_point(size=5)+\n  geom_segment(aes(yend = 0), linetype = \"dashed\", color = \"gray50\")+\n  geom_hline(yintercept=0,linetype='dashed')+\n  #Annotations\n  labs(title='Using CAPM to analyze over/undervalued investment opportunities',\n       subtitle = 'Source: Yahoo! Finance',\n       x = 'Ticker',\n       y = 'Alpha')+\n  #Scales\n  scale_y_continuous(labels = percent)+\n  #Custom 'TidyQuant' theme\n  theme_tq()+\n  #Adding further customizations\n  theme(legend.position='none',\n        axis.title = element_text(face='bold',size=15),\n        axis.text = element_text(size=10),\n        plot.title = element_text(size=20,face='bold'),\n        plot.subtitle  = element_text(size=15,face='bold'))\n```\n:::\n\n\n\n## Output\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-18-1.png){width=1440}\n:::\n:::\n\n\n:::\n\n## CAPM shortcomings\n\n-   In our estimation, none of the $\\small \\alpha$ results were statistically significant, meaning that we cannot reject the hypothesis that $\\alpha$ is different from zero\n\n    1.  In such a way, it implies that investors cannot really earn abnormal returns that are uncorrelated with the market\n    2.  However, many researchers have found [market anomalies]{.blue} where it was possible to create a strategy that generated positive $\\alpha$\n\n-   It is important to recall some of the model's shortcomings:\n\n    1.  Market Returns are really context-dependent, and the use of *NYSE/DOW/Ibovespa* etc is problem-specific\n    2.  The sensitivity to market returns, $\\small \\beta$, might not be stable over time\n    3.  Systematic Risk might not be the [only]{.blue} factor that matters!\n    4.  Assumptions of the CAPM might not be that realistic\n\n## *CAPM* and Efficient Markets\n\n-   The *CAPM* model relates to the *Efficient Market Hypothesis* [@fama1970] by providing a framework to determine expected returns based on a single factor: the [systematic risk]{.blue}\n\n-   Hence, if the *Efficient Market Hypothesis* holds, CAPM should [correctly]{.green} price all assets:\n\n    1.  Expected returns depend only on beta, the sensitivity to systematic risk\n    2.  No other risk factors should systematically predict returns\n\n. . .\n\n**Question**: if the *CAPM* does not hold in practice, does that mean that markets are *inefficient*?\n\n. . .\n\n-   It is tempting to argue that if the *CAPM* [fails]{.red} to account for some market anomalies, it must be that the markets are [not efficient]{.blue} as the model would predict\n\n-   Note, however, that this discussion is more nuanced than simply rejecting the *Efficient Market Hypothesis* altogether\n\n## *CAPM* and Efficient Markets, continued\n\n1.  It is tempting to argue that if the *CAPM* [fails]{.red} to account for some market anomalies, it must be that the markets are [not efficient]{.blue} as the model would predict\n\n2.  Note, however, that this discussion is more nuanced than simply rejecting the *Efficient Market Hypothesis* altogether\n\n-   All in all, testing the *CAPM* is inherently a [joint test]{.blue} of:\n\n    1.  **Market Efficiency** - if the model is correctly specified, there should be no systematic $\\alpha>0$\n    2.  **Model Specification** - there is an omitted factor other than the systematic risk that explains excess returns\n\n-   Therefore, if the *CAPM* fails empirical tests, it is unclear whether it is because **I)**markets are [inefficient]{.blue}; or **II)** the model is simply [misspecified]{.blue}\n\n-   Alternative models, such as the *Fama-French Three-Factor Model* [@fama1993], attempt to address these limitations\n\n## It is now your turn...\n\n- In our *Manipulating Time Series Data* lecture, we recreated the at the [*Deadlift ETF*](https://finance.yahoo.com/news/deadlift-etf-world-latest-headscratcher-140000992.html) and compared it to the returns from the *S&P 500* index\n\n- Now, assuming that the *CAPM* correctly prices all assets, you are equipped to use the model and evaluate whether such strategy yielded *true* skill returns, or $\\small \\alpha$\n\n::: {.callout-tip}\n### Hands-on Exercise\n\n1. Adapt the code we have used in the *Manipulating Time Series Data* to generate the *weekly* returns during 2024 for the *Deadlift ETF*\n2. Merge the dataset with the *Fama French* dataset you have just used. You can use the `left_join` function with the  `by` argument to join two dataframes with different column names\n3. Use `mutate` to create a column that calculates the weekly excess return of the *Deadlift ETF* relative to the risk-free rate\n4. Estimate an OLS regression of the form:\n\n$$\nR_{i,t}=\\alpha+\\beta \\times(R_{m,t}-R_{f,t})+\\varepsilon_{i,t}\n$$\n\nHow do you interpret these findings? Does investing *Deadlift ETF* provide true skill returns? Explain your rationale.\n\n:::\n\n\n## Code snippet from previous classes\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set up the list of assets\ndeadlift=c('META','AMZN','GS','UBER','MSFT','AAPL','BLK','NVDA')\n\n#Set up the starting date\nstart='2020-01-01'\nend='2024-12-31'\n\n#Step 1: Read the Deadlift data using tidyquant\nDeadlift_Performance=deadlift%>%\n  tq_get(from=start,to=end)%>%\n  #Select only the columns of interest\n  select(symbol,date,adjusted)%>%\n  #Group by symbol and date\n  group_by(symbol)%>%\n  #Use tq_transmute to aggregate and calculate weekly returns\n  tq_transmute(selected=adjusted,\n               mutate_fun=yearlyReturn,\n               col_rename = 'Deadlift')%>%\n  #Group by date\n  group_by(date)%>%\n  #Summarize average return (since it is an equally-weighted portfolio)\n  summarize(Deadlift=mean(Deadlift,na.rm=TRUE))\n\n#Step 2: Read the S&P 500 data using tidyquant\nSP500_Performance=tq_get('^GSPC',from=start,to=end)%>%\n  #Select only the columns of interest\n  select(symbol,date,adjusted)%>%\n  #Group by symbol and date\n  group_by(symbol)%>%\n  #Use tq_transmute to aggregate and calculate weekly returns\n  tq_transmute(selected=adjusted,\n               mutate_fun=yearlyReturn,\n               col_rename = 'SP500')%>%\n  ungroup()%>%\n  select(-symbol)\n    \n#Merge\nSP500_Performance%>%\n  inner_join(Deadlift_Performance)%>%\n  mutate(across(where(is.numeric),percent))%>%\n  mutate(date=year(date))%>%\n  setNames(c('Year','S&P 500','DeadLift ETF'))\n```\n:::\n\n\n\n\n## References\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/font-awesome-6.5.2/js/script.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}