{
  "hash": "f767100a67ed7ebb0ac8f2edc4045adb",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data Case II - Factor Harvesting and Portfolio Optimization\"\nauthor: \"Lucas S. Macoris (FGV-EAESP)\"\nformat:\n  html:\n    page-layout: full\neditor: visual\n---\n\n\n\n# About\n\nThis Data Case is part of the *Practical Applications in Quantitative Finance* course, held at FGV-EAESP's undergraduate course in business. Carefully follow the instructions contained in the data case as well as *eClass®* before you make your submission.\n\n## Case Outline\n\nHedge funds operate in a highly competitive environment where their ability to generate alpha---returns beyond market factors---is constantly scrutinized. Many funds claim to deliver superior returns by exploiting inefficiencies, but how much of their performance is just exposure to well-known risk factors?\n\nAs part of the Strategic Investments Division at Sentinel Capital, a multi-billion-dollar *Fund of Funds (FoF)*, your team has been tasked with evaluating the performance of eight hedge funds over the last decade. The ultimate goal? Constructing an optimal portfolio of hedge funds that maximizes returns while managing risk.\n\nTo do this, you'll leverage `R`, `tidyverse`, `tidyquant`, and `PortfolioAnalytics` by applying factor models, portfolio optimization techniques, and rolling performance analysis. Your key tool for evaluation will be the *Fama-French Five-Factor Model*, which decomposes returns into market, size, value, profitability, and investment factors.\n\nYour dataset contains monthly returns from *eight* distinct hedge funds, each with a distinct allocation rationale:\n\n1.  *AlphaSynthesis Capital* -- A long/short equity fund with an emphasis on momentum-driven strategies.\n2.  *ArbVantage Partners* -- A statistical arbitrage fund specializing in mean-reversion strategies.\n3.  *Sentinel Macro Strategies* -- A global macro fund that trades based on macroeconomic indicators.\n4.  *Quantum Volatility Fund* -- A volatility arbitrage fund exploiting implied vs. realized volatility.\n5.  *Horizon Event-Driven* -- A fund that profits from corporate events such as mergers, spin-offs, and earnings surprises.\n6.  *DeepValue Asset Management* -- A deep-value fund investing in undervalued securities based on fundamental analysis.\n7.  *Nova Growth Strategies* -- A growth-oriented hedge fund focusing on technology and high-beta stocks.\n8.  *Vega Capital Neutral* -- A market-neutral strategy that seeks absolute returns with low beta exposure.\n\nYour task is to analyze these funds, compare them against the *Fama-French* three-factor model, and construct optimal hedge fund portfolios.\n\n::: callout-important\n### Deliverable\n\nEach group is expected to deliver a single assignment. A submission must be either an `.R` script or a `.qmd` (Quarto) file, **ensuring that both code and interpretations of the results are clearly presented**. Whenever applicable, include concise explanations alongside your code to demonstrate your understanding of the analysis. The due date for this submission is specified on *eClass®*, so please check the platform for details. You are required to clearly document your workflow and assumptions, and provide meaningful explanations alongside your outputs.\n\nTo help you structure your submission, I have provided a Quarto mock template, which is already available for you to use. This template is designed to help you seamlessly integrate your code and analysis, ensuring a clear and organized presentation of your work. Feel free to use it as a starting point to format your responses effectively. The mock template can be found in the *Data Cases* folder on *eClass®*.\n:::\n\n## Tech-setup\n\nBefore you start, make sure that you have your `R` session correctly configured with all the following packages running the code below:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Package names\npackages <- c(\"tidyverse\",\"tidyquant\",\"tidymodels\",\"xts\", \"glue\",\"scales\",\"PortfolioAnalytics\")\n\n# Install packages not yet installed\ninstalled_packages <- packages %in% rownames(installed.packages())\n\nif (any(installed_packages == FALSE)) {\n  install.packages(packages[!installed_packages])\n}\n\n# Load all packages\ninvisible(lapply(packages, library, character.only = TRUE))\n```\n:::\n\n\n\nAlternatively, you can simply call:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Install if not already available\n  install.packages('tidyverse')\n  install.packages('tidyquant')\n  install.packages('glue')\n  install.packages('scales')\n  install.packages('PortfolioAnalytics')\n\n#Load\n  library(tidyverse)\n  library(tidyquant)\n  library(tidymodels)\n  library(glue)\n  library(scales)\n  library(PortfolioAnalytics)\n```\n:::\n\n\n\n::: callout-important\n### Callout\n\nDepending upon your `R` version that is currently installed, you may or may not have the right set of optimization routines properly set up in your session. To make sure that you can use the portfolio optimization functions from `PortfolioAnalytics` package, install the `DEoptim` (see details [here](https://cran.r-project.org/web/packages/DEoptim/index.html)) that is used on the backend.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages('DEoptim')\n```\n:::\n\n\n:::\n\n## Exercise 1\n\n\n\n::: {.cell}\n\n:::\n\n\n\nDownload the `hf_data.RDS` file on *eClass®*. This dataset covers the period from *January 2010*, to *December 2024* and shows the monthly returns for each hedge fund. Using the functions from the `tidyverse` and `tidyquant` packages, visualize the historical returns of all hedge funds. What trends or anomalies do you observe? Are there periods of exceptional gains or drawdowns? Which fund has shown to be the best performer during the study period?\n\n::: callout-tip\n### Hint\n\n1.  Because `hf_data` is an `data.frame` object, you can pass the `as.xts` to convert it to `xts` and then call `cumprod()` to generate the cumulative returns for all assets. Do not forget to use the `cumprod(1+x)-1` syntax to make sure that you are getting the correct compounded returns over time!\n\n2.  Now, your resulting output can be converted back to a `data.frame` using `as.data.frame()` and getting the `date` column back using `rownames_to_column('date')`. To go from wide to long format, you can use the `pivot_longer` function, keeping only one column for the returns and another column that refers to each strategy at a given date.\n\n3.  You can pipe that into a `ggplot` call, mapping the `date` to the x-axis, the cumulative return column to the y-axis, and the `geom_line()` function to create a bar chart, using the `group` and `color` to color each fund differently. Add as many customizations you think are worth the effort.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(cumprod(1+as.xts(hf_data))-1)%>%\n  as.data.frame()%>%\n  rownames_to_column('date')%>%\n  mutate(date=as.Date(date))%>%\n  pivot_longer(names_to='strategy',values_to = 'cum_return',cols=2:8)%>%\n  ggplot(aes(x=date,y=cum_return,group=strategy,col=strategy))+\n  geom_line(size=1)+\n  scale_x_date(date_breaks = 'years',date_labels='%Y')+\n  scale_y_continuous(labels = label_percent(big.mark = '.'))+\n  labs(title='Comparison of hedge fund  strategies over time',\n       subtitle='Considering daily hedge fund returns.',\n       col='Strategy',\n       x='',\n       y='Cumulative Return')+\n  theme_minimal()+\n  theme(legend.position = 'bottom',\n        axis.text.x = element_text(angle=90,size=12),\n        axis.text.y = element_text(size=12),\n        axis.title = element_text(face='bold',size=15),\n        plot.title = element_text(face='bold',size=20),\n        plot.subtitle  = element_text(size=12))\n```\n\n::: {.cell-output-display}\n![](data-case-2-solutions_files/figure-html/unnamed-chunk-5-1.png){width=1152}\n:::\n:::\n\n\n\n## Exercise 2\n\nDownload the `ff5_data.RDS` file on *eClass®*. This file contains the historical monthly returns for the *Fama-French 5 factor model* for the U.S. stock market. Merge this data with your hedge fund dataset, `hf_data`, and run an *Ordinary Least Squares (OLS)* regression for each fund against the *Fama-French* factors using the following specification:\n\n$$\n\\small E[R_{i,t}] = \\alpha + \\beta_s^M \\times \\underbrace{(E[R_m]− R_f)}_{\\text{Market}}  + \\beta_s^{SMB} \\times \\underbrace{E[R_{SMB}]}_{\\text{Size}} + \\beta_s^{HML} \\times \\underbrace{E[R_{HML}]}_{\\text{Book-to-Market.}} + \\beta_s^{RMW} \\times \\underbrace{E[R_{RMW}]}_{\\text{Profitability}} + \\beta_s^{CMA} \\times \\underbrace{E[R_{CMA}]}_{\\text{Investment}} + \\varepsilon_{i,t}\n$$\n\nBased on the results you found, which funds exhibit significant (at 5% confidence levels) $\\alpha$ after controlling for factor exposures? Store the names of the these funds in an object called `positive_alpha_funds`.\n\n::: callout-tip\n### Hint\n\n1.  Because `hf_data` is in wide format, you can use the `pivot_longer` to transform it to a tidy format - assign it to another object (*e.g*, `hf_returns`) for later use.\n2.  After that, merge this newly created that to the `ff5_data` object using the `left_join` function, and use `mutate` to create the excess returns for each fund by subtracting the risk-free column, assigning it to a new object (*e.g*, `merged_df`)\n3.  Use the functional programming techniques from the `purrr` package (or do a `for-loop`) to map the `lm` and `tidy` functions to each strategy subset, and collect the results from $\\alpha$ (the *Intercept* of the regression).\n4.  Collect the results in an object and use `ggplot` to chart your results.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Read the FF5 Data\nff5_data=readRDS('Assets/ff5_data.RDS')\n\n#Convert the hf_data to a data.frame object and adjust columns\nhf_returns = hf_data%>%\n  pivot_longer(cols = -date,names_to = 'fund',values_to = 'monthly_return')\n\n #Merge both datasets by date\nmerged_df <- hf_returns%>%\n  #Merge\n  left_join(ff5_data, by = \"date\")%>%\n  #Pivot the data for each strategy\n  mutate(excess_return = monthly_return - RF)\n\n#Alpha estimation\nFF_results <- merged_df%>%\n  #Group by strategy\n  group_by(fund)%>%\n  #Nest the data\n  nest()%>%\n  #For each nest, map the lm() function and the tidy function\n  mutate(model = map(data, ~ lm(excess_return ~ MKT_MINUS_RF + HML + SMB + CMA + RMW, data = .)),\n         results = map(model, tidy))%>%\n  #Unnest the results\n  unnest(results)%>%\n  #Select the desired columns\n  select(fund, term, estimate, std.error, p.value)\n\n#Chart\nFF_results %>%\n  filter(term=='(Intercept)')%>%\n  mutate(stat_sig=ifelse(p.value<0.05,'Statistically sig. at 1%','Not statistically sig. at 1%'))%>%\n  ggplot(aes(x=reorder(fund,desc(estimate)),y=estimate,fill=stat_sig))+\n  geom_col(size=3)+\n  geom_text(aes(label = percent(estimate,accuracy=0.01),vjust=-1))+\n  #Annotations\n  labs(title='Which strategies did generate positive and statistically significant alphas?',\n       subtitle = 'Using the Fama-French three-factor model with monthly return data.',\n       x = 'Strategy',\n       y = 'Alpha (%)',\n       fill = 'Stat. Sig')+\n  #Scales\n  scale_y_continuous(labels = percent)+\n  #Custom theme minimal\n  theme_minimal()+\n  #Adding further customizations\n  theme(legend.position='bottom',\n        axis.title = element_text(face='bold',size=15),\n        axis.text = element_text(size=12),\n        plot.title = element_text(size=20,face='bold'),\n        plot.subtitle  = element_text(size=15))\n```\n\n::: {.cell-output-display}\n![](data-case-2-solutions_files/figure-html/unnamed-chunk-6-1.png){width=1152}\n:::\n\n```{.r .cell-code}\n#Positive alpha funds\npositive_alpha_funds=FF_results%>%filter(term=='(Intercept)',estimate>0)%>%pull(fund)\n```\n:::\n\n\n\n## Exercise 4\n\nUsing the results from our previous *OLS* regressions, explain how exposed each fund was to each of the factor portfolios contained in the *Fama-French 5 Factor* model. How can this help you explain the over(under)performance of the top(worst) funds?\n\n::: callout-tip\n### Hint\n\n1.  Using the estimates from the estimation, collect all the $\\beta$s from the regressions by filtering out the *Intercept* using the `filter()` function\n2.  Use `ggplot` to chart the weights (factor betas) for each strategy. To display all strategies in one chart, you can map the factors to the `x` axis, the factor betas values to the `y` axis, use `facet_wrap` to facet your chart by each different fund.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nFF_results %>%\n  filter(term != \"(Intercept)\")%>%\n  group_by(fund)%>%\n  ggplot(aes(x = reorder(term,desc(estimate)), y = estimate, fill = term)) +\n  geom_col(position = position_dodge())+\n  geom_label(aes(label = round(estimate,2)),col='black',fill='white')+\n  theme_minimal()+\n  facet_wrap(fund~.,ncol=2,nrow=4)+\n  #Annotations\n  labs(title = \"Fama-French Factor Loadings by Hedge Fund Strategy\",\n       x = \"Hedge Fund Strategy\",\n       y = \"Factor Loading\",\n       fill = 'Risk Factor')+\n  #Custom theme minimal\n  theme_minimal()+\n  #Adding further customizations\n  theme(legend.position='bottom',\n        axis.title = element_text(face='bold',size=15),\n        axis.text = element_blank(),\n        plot.title = element_text(size=20,face='bold'),\n        plot.subtitle  = element_text(size=15))\n```\n\n::: {.cell-output-display}\n![](data-case-2-solutions_files/figure-html/unnamed-chunk-7-1.png){width=1152}\n:::\n:::\n\n\n\n## Exercise 4\n\nWay to go! Your boss was really impressed with how you were able to dissect the returns from individual hedge funds and understand which factors drove performance, and in which cases we were able to find positive returns that were uncorrelated with any of the risk factors. Now, it is time to start building portfolios by allocating money across each fund using the *Markowitz Mean-Variance* optimization rationale.\n\nTo do that, start by filtering your sample to consider only the hedge funds that were able to generate $\\alpha$ throughout the whole period. Divide your sample using a $50\\%/50\\%$ split, using information from $2010$ until $2018$ as a *training* set, and $2019$ to $2024$ as a *test* set. Construct a *Minimum-Variance Portfolio* of the following format:\n\n$$\n\\min_{\\{w_1,w_2...,w_n\\}} \\sigma^2_p = w^T \\Sigma w,\n\\text{ such that:}\n\\\\\n\\begin{cases}\n\\sum_{i=1}^n w_i=1 \\text{ (1)}\\\\\n0.05\\leq w_i \\leq 0.50, \\forall i \\text{ (2)}\n\\end{cases}\n$$\n\nIn other words, you are solving the following problem: find the set of allocation weights $w_1,w_2,w_3,...,w_n$ (the % that you allocate in each of the strategies) that, when used to create a portfolio, are the ones that create the portfolio with the *minimum variance* among all possible combinations. In order to do that, you have to ensure that the weights add up to $100\\%$ (so you're fully investing your capital), which is the first condition. The second conditions states that neither stock can have a weight that is lower than $5\\%$ nor have a weight that is greater than $50\\%$.\n\nNote that $w^T\\Sigma w$ is nothing more than the matrix form of $\\sum_{i=1}^{N}w_i\\sigma_i^2+ 2\\sum_{i=1}^{N}\\sum_{j\\neq i}w_i w_j\\sigma_{i,j}$, which is the variance of a portfolio that consists of $N$ assets.\n\nUsing the *training* sample and *only the funds* that have shown $\\alpha>0$ (regardless of the statistical significance), what is the optimal allocation? Store this into an object called `min_var_allocation`.\n\n::: callout-tip\n### Hint\n\n1.  Filter the `hf_data` to contain only the `date` and the columns that refer to the strategies with positive $\\alpha$.\n\n2.  Use the `as.xts` to transform the object from a `data.frame` to an `xts` object. This is crucial, as the functions from the `PortfolioAnalytics` operate on `xts` objects. With your newly created `xts` object, create two new objects, `training_sample` and `testing_sample` using the `xts` subsetting syntax:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntraining_sample=(your_filtered_hf_data%>%as.xts())['2010/2018']\ntest_sample=(your_filtered_hf_data%>%as.xts())['2019/2024']\n```\n:::\n\n\n\n3.  Use the `portfolio.spec` and the `optimize.portfolio` functions from the `PortfolioAnalytics` package to define and optimize the portfolio using the syntax we have learned during class. If you are unsure on what to do here, please refer to the `workbook.R` file that we have gone through for a similar replication.\n\n4.  Finally, use the `extractWeights` function to output a table with the optimal weights.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Transform into .xts and split the sample\nfiltered_hf_data=hf_data%>%select(date,all_of(positive_alpha_funds))\ntraining_sample=(filtered_hf_data%>%as.xts())['2010/2018']\ntest_sample=(filtered_hf_data%>%as.xts())['2019/2024']\n\n\n#Risk Minimization\nmin_var_portfolio <- portfolio.spec(assets = positive_alpha_funds)%>% \n  add.objective(type = \"risk\", name = \"var\")%>%\n  add.constraint(type = \"full_investment\")%>%\n  add.constraint(type = \"box\", min = 0.05, max = 0.5)\n\nmin_var_allocation <- training_sample %>% \n  optimize.portfolio(\n    portfolio = min_var_portfolio\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIteration: 1 bestvalit: 0.033117 bestmemit:    0.054000    0.440000    0.052000    0.454000\nIteration: 2 bestvalit: 0.033117 bestmemit:    0.054000    0.440000    0.052000    0.454000\nIteration: 3 bestvalit: 0.033117 bestmemit:    0.054000    0.440000    0.052000    0.454000\nIteration: 4 bestvalit: 0.033117 bestmemit:    0.054000    0.440000    0.052000    0.454000\nIteration: 5 bestvalit: 0.033117 bestmemit:    0.054000    0.440000    0.052000    0.454000\nIteration: 6 bestvalit: 0.033117 bestmemit:    0.054000    0.440000    0.052000    0.454000\nIteration: 7 bestvalit: 0.033117 bestmemit:    0.054000    0.440000    0.052000    0.454000\nIteration: 8 bestvalit: 0.033117 bestmemit:    0.054000    0.440000    0.052000    0.454000\n[1] 0.054 0.440 0.052 0.454\n```\n\n\n:::\n\n```{.r .cell-code}\n#Get the weights\nextractWeights(min_var_allocation)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nalphasynthesis     arbvantage       sentinel        horizon \n         0.054          0.440          0.052          0.454 \n```\n\n\n:::\n:::\n\n\n\n## Exercise 5\n\nUsing the *training* sample and *only the funds* that have shown $\\alpha>0$, develop a portfolio that maximizes returns instead of minimizing risk. What is the optimal allocation? Store this into an object called `max_return_allocation`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Return Maximization\nmax_return_portfolio <- portfolio.spec(assets = positive_alpha_funds)%>% \n  add.objective(type = \"return\", name = \"mean\")%>%\n  add.constraint(type = \"full_investment\")%>%\n  add.constraint(type = \"box\", min = 0.05, max = 0.5)\n\nmax_return_allocation <- training_sample %>% \n  optimize.portfolio(\n    portfolio = max_return_portfolio\n    )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIteration: 1 bestvalit: -0.010391 bestmemit:    0.358000    0.060000    0.492000    0.090000\nIteration: 2 bestvalit: -0.010391 bestmemit:    0.358000    0.060000    0.492000    0.090000\nIteration: 3 bestvalit: -0.010391 bestmemit:    0.358000    0.060000    0.492000    0.090000\nIteration: 4 bestvalit: -0.010391 bestmemit:    0.358000    0.060000    0.492000    0.090000\nIteration: 5 bestvalit: -0.010391 bestmemit:    0.358000    0.060000    0.492000    0.090000\nIteration: 6 bestvalit: -0.010391 bestmemit:    0.358000    0.060000    0.492000    0.090000\nIteration: 7 bestvalit: -0.010391 bestmemit:    0.358000    0.060000    0.492000    0.090000\n[1] 0.358 0.060 0.492 0.090\n```\n\n\n:::\n\n```{.r .cell-code}\n#Get the weights\nextractWeights(max_return_allocation)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nalphasynthesis     arbvantage       sentinel        horizon \n         0.358          0.060          0.492          0.090 \n```\n\n\n:::\n:::\n\n\n\n## Exercise 6\n\nUsing the *training* sample and *only the funds* that have shown $\\alpha>0$, develop a portfolio that maximizes the *Sharpe-Ratio* - *i.e*, maximizes the risk-adjusted returns. What is the optimal allocation? Store this into an object called `max_sharpe_allocation`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Return Maximization\nmax_sharpe_portfolio <- portfolio.spec(assets = positive_alpha_funds)%>% \n  add.objective(type = \"return\", name = \"mean\")%>% \n  add.objective(type = \"risk\", name = \"StdDev\")%>%\n  add.constraint(type = \"full_investment\")%>%\n  add.constraint(type = \"box\", min = 0.05, max = 0.5)\n\nmax_sharpe_allocation <- training_sample %>% \n  optimize.portfolio(\n    portfolio = max_sharpe_portfolio,\n    SR= TRUE\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIteration: 1 bestvalit: 0.025895 bestmemit:    0.196000    0.338000    0.132000    0.334000\nIteration: 2 bestvalit: 0.024438 bestmemit:    0.134000    0.302000    0.082000    0.482000\nIteration: 3 bestvalit: 0.024390 bestmemit:    0.052000    0.490000    0.088000    0.370000\nIteration: 4 bestvalit: 0.024390 bestmemit:    0.052000    0.490000    0.088000    0.370000\nIteration: 5 bestvalit: 0.024390 bestmemit:    0.052000    0.490000    0.088000    0.370000\nIteration: 6 bestvalit: 0.024390 bestmemit:    0.052000    0.490000    0.088000    0.370000\nIteration: 7 bestvalit: 0.024390 bestmemit:    0.052000    0.490000    0.088000    0.370000\nIteration: 8 bestvalit: 0.024390 bestmemit:    0.052000    0.490000    0.088000    0.370000\nIteration: 9 bestvalit: 0.024390 bestmemit:    0.052000    0.490000    0.088000    0.370000\nIteration: 10 bestvalit: 0.024390 bestmemit:    0.052000    0.490000    0.088000    0.370000\n[1] 0.052 0.490 0.088 0.370\n```\n\n\n:::\n\n```{.r .cell-code}\n#Get the weights\nextractWeights(max_sharpe_allocation)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nalphasynthesis     arbvantage       sentinel        horizon \n         0.052          0.490          0.088          0.370 \n```\n\n\n:::\n:::\n\n\n\n## Exercise 7\n\nCompare the optimal weights across each strategy and discuss the allocations. Is there any better allocation rule?\n\n::: callout-tip\n### Hint\n\n1.  After collecting your optimal weights using the `extractWeights` function and storing them into separate objects, use the `rbind` function to bind them together in a row-wise manner and transform it to a `data.frame` using the `as.data.frame()` function.\n2.  Add a new column that describes which strategy is contained in each row.\n3.  Use the `pivot_longer` to transform the data to a tidy format, making it easier for you to pipe the output into a `ggplot` call.\n\nFor these steps, you can use the following syntax:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrbind(extractWeights(min_var_allocation),\n      extractWeights(max_return_allocation),\n      extractWeights(max_sharpe_allocation))%>%\n  as.data.frame()%>%\n  mutate(objective=c('Minimize Variance','Maximize Returns','Maximize Sharpe'))%>%\n  pivot_longer(1:4,names_to = 'fund',values_to = 'weights')\n```\n:::\n\n\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Chart weights\nrbind(extractWeights(min_var_allocation),\n      extractWeights(max_return_allocation),\n      extractWeights(max_sharpe_allocation))%>%\n  as.data.frame()%>%\n  mutate(objective=c('Minimize Variance','Maximize Returns','Maximize Sharpe'))%>%\n  pivot_longer(1:4,names_to = 'fund',values_to = 'weights')%>%\n  ggplot(aes(x = objective, y = weights, fill = fund)) +\n  geom_col() + \n  geom_text(aes(label = percent(weights)),\n            position = position_stack(vjust = .6),\n            size = 6) + \n  scale_x_discrete(labels = c(\"Maximize Return\", \"Minimize Risk\", \"Max Sharpe Ratio\")) +\n  scale_y_continuous(labels=scales::percent)+\n  labs(x = \"\", y = \"Allocation (%)\",\n       title = \"Asset Allocation by Optimization Criteria\")+\n  theme_minimal()+\n  theme(legend.position='bottom',\n        axis.title = element_text(face='bold',size=15),\n        axis.text = element_text(size=12),\n        plot.title = element_text(size=20,face='bold'),\n        plot.subtitle  = element_text(size=15))\n```\n\n::: {.cell-output-display}\n![](data-case-2-solutions_files/figure-html/unnamed-chunk-13-1.png){width=1152}\n:::\n:::\n\n\n\n## Exercise 8\n\nCompare the historical performance from each fund in the *testing* sample. To do that, use the three sets of optimal weights you have just created (`min_var_allocation`, `max_return_allocation`, and `max_sharpe_allocation`) along with the `tq_portfolio` function to estimate the returns in the *test* sample, rebalancing it monthly. Which strategy did deliver the highest out-of-sample returns? Did they outperform a *naive* portfolio using equal weights to all funds?\n\n::: callout-tip\n### Hint\n\n1.  Use the `hf_returns` data you have created in the beginning of the exercise (*i.e*, the dataset of hedge fund returns in long format) and apply the `filter` function to keep only the rows where i) the fund is in the list of funds with positive alpha (*i.e*, it is in the `positive_alpha_funds` you have created before) and `year(date)>2018` (*i.e*, belongs to testing sample).\n2.  Use the `tq_portfolio` function using the following syntax to calculate the historical returns of the portfolio:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  tq_portfolio(\n    assets_col = fund, #This is the column that contains the fund names\n    returns_col = monthly_return, #Column that contains the monthly returns\n    weights = extractWeights(min_var_allocation), #The portfolio.spec you have created\n    col_rename = \"returns_min_var\",\n    rebalance_on = \"months\"\n  )\n```\n:::\n\n\n\n3.  Do this for all three portfolio specifications, assigning their results to separate objects. For the naive portfolio, you can assign a vector of equal weights using the `rep(weight,number_of_replications)` syntax.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Minimize Risk Portfolio\n\nmin_var_performance <- hf_returns%>%\n  filter(fund %in% positive_alpha_funds, year(date)>2018)%>%\n  tq_portfolio(\n    assets_col = fund,\n    returns_col = monthly_return,\n    weights = extractWeights(min_var_allocation),\n    col_rename = \"returns_min_var\",\n    rebalance_on = \"months\"\n  )\n\n#Maximize Return Portfolio\n\nmax_return_performance <- hf_returns%>%\n  filter(fund %in% positive_alpha_funds, year(date)>2018)%>%\n  tq_portfolio(\n    assets_col = fund,\n    returns_col = monthly_return,\n    weights = extractWeights(max_return_allocation),\n    col_rename = \"returns_max_return\",\n    rebalance_on = \"months\"\n  )\n\n#Naive Portfolio\n\nmax_sharpe_performance <- hf_returns%>%\n  filter(fund %in% positive_alpha_funds, year(date)>2018)%>%\n  tq_portfolio(\n    assets_col = fund,\n    returns_col = monthly_return,\n    weights = extractWeights(max_sharpe_allocation),\n    col_rename = \"returns_max_sharpe\",\n    rebalance_on = \"months\"\n  )\n\n#Naive Portfolio\n\nnaive_performance <- hf_returns%>%\n  filter(fund %in% positive_alpha_funds, year(date)>2018)%>%\n  tq_portfolio(\n    assets_col = fund,\n    returns_col = monthly_return,\n    weights = rep(0.25,4),\n    col_rename = \"returns_naive\",\n    rebalance_on = \"months\"\n  )\n\n#Chart\n\nnaive_performance%>%\n  left_join(min_var_performance)%>%\n  left_join(max_return_performance)%>%\n  left_join(max_sharpe_performance)%>%\n  pivot_longer(cols = \"returns_naive\":\"returns_max_sharpe\",\n               names_to = \"strategy\",\n               values_to = \"return\") %>% \n  mutate(strategy = case_when(strategy == \"returns_max_return\" ~ \"Maximize Avg. Return\",\n                                strategy == \"returns_min_var\" ~ \"Minimize risk\",\n                                strategy == \"returns_naive\" ~ \"Equal Allocation\",\n                                strategy == \"returns_max_sharpe\" ~ \"Maximize Sharpe Ratio\")) %>% \n  group_by(strategy) %>% \n  mutate(cum_return = cumprod(1+return)-1) %>% \n  ggplot(aes(x = date, y = cum_return, color = strategy)) + \n  geom_line(size = 1.2)+ \n  scale_y_continuous(label = scales::percent) +\n  labs(title = \"Historical Performance over test sample\", y = \"Cumulative Return\",\n       x = \"\",\n       color='') + \n  theme_minimal()+\n  theme(legend.position='bottom',\n      axis.title = element_text(face='bold',size=15),\n      axis.text = element_text(size=12),\n      plot.title = element_text(size=20,face='bold'),\n      plot.subtitle  = element_text(size=15))\n```\n\n::: {.cell-output-display}\n![](data-case-2-solutions_files/figure-html/unnamed-chunk-15-1.png){width=1152}\n:::\n\n```{.r .cell-code}\n#Table\nnaive_performance%>%\n  left_join(min_var_performance)%>%\n  left_join(max_return_performance)%>%\n  left_join(max_sharpe_performance)%>%\n  as.xts()%>%\n  Return.cumulative()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  returns_naive returns_min_var returns_max_return\nCumulative Return     0.9067833       0.8617784          0.8948185\n                  returns_max_sharpe\nCumulative Return          0.8771747\n```\n\n\n:::\n:::\n\n\n\n## Exercise 9\n\nUsing the `max_return_portfolio` object and the `test_sample` data cut, implement a rolling-window optimization to find the optimal portfolio weights. Use a training period and a rolling window of $12$ months, and rebalance the portfolio monthly. How do these dynamically adjusted weights perform compared to static allocations?\n\n::: callout-tip\n### Hint\n\n1.  Using the `test_sample` `xts` object you have created, apply the `optimize.portfolio.rebalancing` function, pointing to the `max_return_portfolio` and the aforementioned parameters for the training period, rolling window, and rebalancing period. You can use the following syntax:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Rolling optimization\nrolling_optimization <- test_sample%>%\n  optimize.portfolio.rebalancing(\n    portfolio = max_return_portfolio,\n    rebalance_on = \"months\",\n    training_period = 12,\n    rolling_window = 12\n  )\n```\n:::\n\n\n\n2.  After you have optimized your portfolio, call `extractWeights` and pipe that into `ggplot` to chart your results.\n:::\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Chart\nextractWeights(rolling_optimization)%>%\n  as.data.frame()%>%\n  rownames_to_column(\"date\")%>% \n  mutate(date = as.Date(date)) %>% \n  pivot_longer(names_to = 'symbol',values_to = 'weights',cols=where(is.numeric)) %>% \n  ggplot(aes(x = date, y = weights, fill = symbol)) +\n  labs(fill = \"\", x = \"\", y = \"Asset Weight\",\n       title = \"Weights under rolling optimization - Maximize Returns\") +\n  geom_col() +\n  scale_x_date(date_breaks = \"6 months\") +\n  scale_y_continuous(labels=scales::percent)+\n  theme_minimal()+\n  theme(legend.position='bottom',\n        axis.title = element_text(face='bold',size=15),\n        axis.text = element_text(size=12),\n        axis.text.x = element_text(angle=90),\n        plot.title = element_text(size=20,face='bold'),\n        plot.subtitle  = element_text(size=15))\n```\n\n::: {.cell-output-display}\n![](data-case-2-solutions_files/figure-html/unnamed-chunk-18-1.png){width=1152}\n:::\n:::\n\n\n\n## Exercise 10\n\nLooking only at the *test* sample period (*i.e*, from $2019$ to $2024$, chart the historical performance of the dynamically-optimized portfolio *vis-a-vis* the static portfolios you have just created. Are there any gains stemming from dynamically optimizing the portfolio?\n\n::: callout-tip\n### Hint\n\n1.  Use the `extractWeights()` function on the dynamically optimized portfolio optimization object to collect a time series of weight allocations.\n\n2.  With that, use `as_data_frame()` and `rownames_to_column(\"date\")` to transform it to a `data.frame` with a `date` column identifier.\n\n3.  Finally, transform it to long format using the `pivot_longer()` function.\n\n4.  Do a similar procedure for the `xts` object where you stored the test sample returns (in my example, `test_sample`)\n\n5.  Use `left_join` to merge both datasets. You can use a combination of `mutate()` and `summarize()` to calculate the portfolio returns on each date in a step-wise manner:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndynamic_performance=left_join(weights,returns)%>% # Your weights and returns data.frames\n  mutate(ind_return=returns*weights)%>% # Calculate individual returns for each fund on each date\n  group_by(date)%>% # Group by date\n  summarize(returns_dynamic=sum(ind_return,na.rm=TRUE)) # Summing up yields a weighted average of returns by each date\n```\n:::\n\n\n\n6.  Join this `data.frame` with the other objects that contain the historical returns from the other allocation strategies and pipe that into `ggplot`.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweights=extractWeights(rolling_optimization)%>%\n  as.data.frame()%>%\n  rownames_to_column(\"date\")%>% \n  mutate(date = as.Date(date)) %>% \n  pivot_longer(names_to = 'fund',values_to = 'weights',cols=where(is.numeric))\n\nreturns=test_sample%>%\n  as.data.frame()%>%\n  rownames_to_column(\"date\")%>% \n  mutate(date = as.Date(date)) %>% \n  pivot_longer(names_to = 'fund',values_to = 'returns',cols=where(is.numeric))\n\ndynamic_performance=left_join(weights,returns)%>%\n  mutate(ind_return=returns*weights)%>%\n  group_by(date)%>%\n  summarize(returns_dynamic=sum(ind_return,na.rm=TRUE))\n\ndynamic_performance%>%\n  left_join(min_var_performance)%>%\n  left_join(max_return_performance)%>%\n  left_join(max_sharpe_performance)%>%\n  left_join(naive_performance)%>%\n  pivot_longer(cols = \"returns_dynamic\":\"returns_naive\",\n               names_to = \"strategy\",\n               values_to = \"return\")%>% \n  mutate(strategy = case_when(strategy == \"returns_max_return\" ~ \"Maximize Avg. Return\",\n                                strategy == \"returns_min_var\" ~ \"Minimize risk\",\n                                strategy == \"returns_naive\" ~ \"Equal Allocation\",\n                                strategy == \"returns_max_sharpe\" ~ \"Maximize Sharpe Ratio\",\n                                .default = \"Dynamic Portfolio\")) %>%\n  group_by(strategy) %>% \n  mutate(cum_return = cumprod(1+return)-1) %>% \n  ggplot(aes(x = date, y = cum_return, color = strategy)) + \n  geom_line(size = 1.2)+ \n  scale_y_continuous(label = scales::percent) +\n  labs(title = \"Dynamic vis-a-vis static portfolios\", y = \"Cumulative Return\",\n       x = \"\",\n       color='') + \n  theme_minimal()+\n  theme(legend.position='bottom',\n        axis.title = element_text(face='bold',size=15),\n        axis.text = element_text(size=12),\n        plot.title = element_text(size=20,face='bold'),\n        plot.subtitle  = element_text(size=15))\n```\n\n::: {.cell-output-display}\n![](data-case-2-solutions_files/figure-html/unnamed-chunk-20-1.png){width=1152}\n:::\n\n```{.r .cell-code}\n#Table\ndynamic_performance%>%\n  left_join(min_var_performance)%>%\n  left_join(max_return_performance)%>%\n  left_join(max_sharpe_performance)%>%\n  left_join(naive_performance)%>%\n  as.xts()%>%\n  Return.cumulative()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  returns_dynamic returns_min_var returns_max_return\nCumulative Return        1.208376       0.7725337          0.7148009\n                  returns_max_sharpe returns_naive\nCumulative Return          0.7903378     0.7647151\n```\n\n\n:::\n:::\n",
    "supporting": [
      "data-case-2-solutions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}